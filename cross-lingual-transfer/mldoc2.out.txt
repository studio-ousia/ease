gpuhost13
Could not find conda environment: pytorch-1.6
You can list all discoverable environments with `conda info --envs`.

comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/160 [00:00<?, ?it/s]  1%|          | 1/160 [00:00<02:33,  1.03it/s]  1%|â–         | 2/160 [00:01<02:00,  1.31it/s]  2%|â–         | 3/160 [00:01<01:36,  1.62it/s]  2%|â–Ž         | 4/160 [00:01<01:20,  1.94it/s]  3%|â–Ž         | 5/160 [00:02<01:09,  2.25it/s]  4%|â–         | 6/160 [00:02<01:00,  2.54it/s]  4%|â–         | 7/160 [00:02<00:55,  2.78it/s]  5%|â–Œ         | 8/160 [00:02<00:50,  2.98it/s]  6%|â–Œ         | 9/160 [00:03<00:47,  3.15it/s]  6%|â–‹         | 10/160 [00:03<00:45,  3.29it/s]                                                {'loss': 1.3357, 'learning_rate': 9.375000000000001e-06, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:03<00:45,  3.29it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.17it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.69it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  4.00it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.64it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.42it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.28it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s][A                                                
                                             [A{'eval_loss': 1.241909146308899, 'eval_accuracy': 0.548, 'eval_runtime': 2.6219, 'eval_samples_per_second': 381.397, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:06<00:45,  3.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s][A
                                             [A  7%|â–‹         | 11/160 [00:11<06:50,  2.75s/it]  8%|â–Š         | 12/160 [00:12<04:57,  2.01s/it]  8%|â–Š         | 13/160 [00:12<03:39,  1.49s/it]  9%|â–‰         | 14/160 [00:12<02:44,  1.13s/it]  9%|â–‰         | 15/160 [00:13<02:06,  1.14it/s] 10%|â–ˆ         | 16/160 [00:13<01:40,  1.44it/s] 11%|â–ˆ         | 17/160 [00:13<01:21,  1.75it/s] 11%|â–ˆâ–        | 18/160 [00:13<01:08,  2.08it/s] 12%|â–ˆâ–        | 19/160 [00:14<00:59,  2.37it/s] 12%|â–ˆâ–Ž        | 20/160 [00:14<00:52,  2.65it/s]                                                {'loss': 1.1764, 'learning_rate': 8.750000000000001e-06, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:14<00:52,  2.65it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.08it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.41it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:01<00:00,  3.27it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s][A                                                
                                             [A{'eval_loss': 1.0152804851531982, 'eval_accuracy': 0.675, 'eval_runtime': 2.624, 'eval_samples_per_second': 381.09, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:17<00:52,  2.65it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s][A
                                             [A 13%|â–ˆâ–Ž        | 21/160 [00:22<06:30,  2.81s/it] 14%|â–ˆâ–        | 22/160 [00:23<04:42,  2.05s/it] 14%|â–ˆâ–        | 23/160 [00:23<03:27,  1.52s/it] 15%|â–ˆâ–Œ        | 24/160 [00:23<02:35,  1.14s/it] 16%|â–ˆâ–Œ        | 25/160 [00:24<01:59,  1.13it/s] 16%|â–ˆâ–‹        | 26/160 [00:24<01:33,  1.43it/s] 17%|â–ˆâ–‹        | 27/160 [00:24<01:16,  1.74it/s] 18%|â–ˆâ–Š        | 28/160 [00:24<01:03,  2.07it/s] 18%|â–ˆâ–Š        | 29/160 [00:25<00:55,  2.37it/s] 19%|â–ˆâ–‰        | 30/160 [00:25<00:49,  2.64it/s]                                                {'loss': 0.9558, 'learning_rate': 8.125000000000001e-06, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:25<00:49,  2.64it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.08it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.64it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.97it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                
                                             [A{'eval_loss': 0.8168814182281494, 'eval_accuracy': 0.686, 'eval_runtime': 2.6323, 'eval_samples_per_second': 379.892, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:28<00:49,  2.64it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 19%|â–ˆâ–‰        | 31/160 [00:33<06:06,  2.84s/it] 21%|â–ˆâ–ˆ        | 33/160 [00:34<04:19,  2.04s/it] 21%|â–ˆâ–ˆâ–       | 34/160 [00:34<03:10,  1.51s/it] 22%|â–ˆâ–ˆâ–       | 35/160 [00:34<02:22,  1.14s/it] 22%|â–ˆâ–ˆâ–Ž       | 36/160 [00:35<01:49,  1.13it/s] 23%|â–ˆâ–ˆâ–Ž       | 37/160 [00:35<01:26,  1.43it/s] 24%|â–ˆâ–ˆâ–       | 38/160 [00:35<01:09,  1.75it/s] 24%|â–ˆâ–ˆâ–       | 39/160 [00:36<00:58,  2.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:36<00:50,  2.37it/s]                                                {'loss': 0.7501, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:36<00:50,  2.37it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.06it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                
                                             [A{'eval_loss': 0.6802606582641602, 'eval_accuracy': 0.757, 'eval_runtime': 2.637, 'eval_samples_per_second': 379.215, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:38<00:50,  2.37it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 26%|â–ˆâ–ˆâ–Œ       | 41/160 [00:44<05:38,  2.85s/it] 26%|â–ˆâ–ˆâ–‹       | 42/160 [00:45<04:04,  2.07s/it] 27%|â–ˆâ–ˆâ–‹       | 43/160 [00:45<02:59,  1.54s/it] 28%|â–ˆâ–ˆâ–Š       | 44/160 [00:45<02:14,  1.16s/it] 28%|â–ˆâ–ˆâ–Š       | 45/160 [00:45<01:43,  1.12it/s] 29%|â–ˆâ–ˆâ–‰       | 46/160 [00:46<01:21,  1.40it/s] 29%|â–ˆâ–ˆâ–‰       | 47/160 [00:46<01:05,  1.72it/s] 30%|â–ˆâ–ˆâ–ˆ       | 48/160 [00:46<00:55,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆ       | 49/160 [00:47<00:47,  2.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:47<00:42,  2.61it/s]                                                {'loss': 0.6078, 'learning_rate': 6.875e-06, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:47<00:42,  2.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                
                                             [A{'eval_loss': 0.5236819982528687, 'eval_accuracy': 0.826, 'eval_runtime': 2.6418, 'eval_samples_per_second': 378.535, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:49<00:42,  2.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 32%|â–ˆâ–ˆâ–ˆâ–      | 51/160 [00:55<05:09,  2.84s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/160 [00:56<03:43,  2.07s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/160 [00:56<02:44,  1.53s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 54/160 [00:56<02:02,  1.16s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 55/160 [00:57<01:34,  1.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/160 [00:57<01:14,  1.40it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 57/160 [00:57<00:59,  1.72it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 58/160 [00:57<00:50,  2.03it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 59/160 [00:58<00:43,  2.33it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [00:58<00:38,  2.60it/s]                                                {'loss': 0.5013, 'learning_rate': 6.25e-06, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [00:58<00:38,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
{'eval_loss': 0.41713735461235046, 'eval_accuracy': 0.881, 'eval_runtime': 2.6397, 'eval_samples_per_second': 378.832, 'epoch': 1.88}
                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:01<00:38,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 61/160 [01:07<04:47,  2.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 62/160 [01:07<03:27,  2.12s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 63/160 [01:07<02:31,  1.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 65/160 [01:08<01:49,  1.15s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/160 [01:08<01:23,  1.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/160 [01:08<01:05,  1.41it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/160 [01:08<00:53,  1.73it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 69/160 [01:09<00:44,  2.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:09<00:38,  2.34it/s]                                                {'loss': 0.407, 'learning_rate': 5.625e-06, 'epoch': 2.19}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:09<00:38,  2.34it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.06it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.3544907867908478, 'eval_accuracy': 0.885, 'eval_runtime': 2.6402, 'eval_samples_per_second': 378.766, 'epoch': 2.19}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:12<00:38,  2.34it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 71/160 [01:18<04:39,  3.14s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/160 [01:19<03:20,  2.28s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 73/160 [01:19<02:25,  1.68s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/160 [01:19<01:48,  1.26s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 75/160 [01:20<01:22,  1.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/160 [01:20<01:03,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 77/160 [01:20<00:50,  1.63it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 78/160 [01:20<00:42,  1.95it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 79/160 [01:21<00:35,  2.26it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:21<00:31,  2.55it/s]                                                {'loss': 0.3076, 'learning_rate': 5e-06, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:21<00:31,  2.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.3259977400302887, 'eval_accuracy': 0.897, 'eval_runtime': 2.6388, 'eval_samples_per_second': 378.959, 'epoch': 2.5}
                                             [A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:24<00:31,  2.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 81/160 [01:30<03:59,  3.03s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/160 [01:30<02:51,  2.20s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 83/160 [01:31<02:05,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 84/160 [01:31<01:32,  1.22s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 85/160 [01:31<01:10,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 86/160 [01:32<00:54,  1.36it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 87/160 [01:32<00:43,  1.67it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 88/160 [01:32<00:36,  1.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 89/160 [01:32<00:30,  2.30it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:33<00:27,  2.59it/s]                                                {'loss': 0.3038, 'learning_rate': 4.3750000000000005e-06, 'epoch': 2.81}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:33<00:27,  2.59it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.3052320182323456, 'eval_accuracy': 0.895, 'eval_runtime': 2.6389, 'eval_samples_per_second': 378.949, 'epoch': 2.81}

                                             [A 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:35<00:27,  2.59it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 91/160 [01:41<03:20,  2.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 92/160 [01:42<02:24,  2.12s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 93/160 [01:42<01:45,  1.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 94/160 [01:42<01:18,  1.18s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 95/160 [01:43<00:59,  1.09it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 97/160 [01:43<00:43,  1.44it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 98/160 [01:43<00:35,  1.76it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 99/160 [01:43<00:29,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:44<00:25,  2.37it/s]                                                 {'loss': 0.2043, 'learning_rate': 3.7500000000000005e-06, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:44<00:25,  2.37it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 {'eval_loss': 0.2822034955024719, 'eval_accuracy': 0.905, 'eval_runtime': 2.6502, 'eval_samples_per_second': 377.337, 'epoch': 3.12}
                                             [A 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:46<00:25,  2.37it/s]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 101/160 [01:53<03:01,  3.08s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/160 [01:53<02:09,  2.24s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 103/160 [01:54<01:33,  1.65s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 104/160 [01:54<01:09,  1.24s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 105/160 [01:54<00:52,  1.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 106/160 [01:54<00:40,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 107/160 [01:55<00:32,  1.65it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 108/160 [01:55<00:26,  1.97it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 109/160 [01:55<00:22,  2.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:56<00:19,  2.56it/s]                                                 {'loss': 0.2023, 'learning_rate': 3.125e-06, 'epoch': 3.44}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:56<00:19,  2.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             [A{'eval_loss': 0.28934893012046814, 'eval_accuracy': 0.903, 'eval_runtime': 2.6466, 'eval_samples_per_second': 377.837, 'epoch': 3.44}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:58<00:19,  2.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 111/160 [02:05<02:25,  2.97s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 112/160 [02:05<01:43,  2.16s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 113/160 [02:05<01:15,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 114/160 [02:05<00:55,  1.20s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 115/160 [02:06<00:41,  1.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 116/160 [02:06<00:32,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 117/160 [02:06<00:25,  1.68it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/160 [02:06<00:20,  2.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 119/160 [02:07<00:17,  2.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:07<00:15,  2.58it/s]                                                 {'loss': 0.2195, 'learning_rate': 2.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:07<00:15,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             [A{'eval_loss': 0.260446161031723, 'eval_accuracy': 0.904, 'eval_runtime': 2.6435, 'eval_samples_per_second': 378.293, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:10<00:15,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 121/160 [02:16<01:58,  3.04s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 122/160 [02:17<01:23,  2.21s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 123/160 [02:17<01:00,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 124/160 [02:17<00:44,  1.23s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 125/160 [02:17<00:32,  1.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 126/160 [02:18<00:25,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 127/160 [02:18<00:19,  1.65it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 129/160 [02:18<00:14,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:19<00:12,  2.38it/s]                                                 {'loss': 0.193, 'learning_rate': 1.8750000000000003e-06, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:19<00:12,  2.38it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             [A{'eval_loss': 0.283810019493103, 'eval_accuracy': 0.898, 'eval_runtime': 2.6455, 'eval_samples_per_second': 378.006, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:21<00:12,  2.38it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/160 [02:27<01:25,  2.96s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 132/160 [02:28<01:00,  2.16s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 133/160 [02:28<00:43,  1.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/160 [02:28<00:31,  1.20s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 135/160 [02:29<00:23,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 136/160 [02:29<00:17,  1.37it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 137/160 [02:29<00:13,  1.68it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 138/160 [02:29<00:10,  2.01it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 139/160 [02:30<00:09,  2.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:30<00:07,  2.58it/s]                                                 {'loss': 0.1533, 'learning_rate': 1.25e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:30<00:07,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.81it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.63it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                 
                                             [A{'eval_loss': 0.2738199532032013, 'eval_accuracy': 0.902, 'eval_runtime': 2.6421, 'eval_samples_per_second': 378.486, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:33<00:07,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 141/160 [02:39<00:58,  3.09s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 142/160 [02:40<00:40,  2.24s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 143/160 [02:40<00:28,  1.65s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 144/160 [02:40<00:19,  1.24s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 145/160 [02:40<00:14,  1.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 146/160 [02:41<00:10,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/160 [02:41<00:07,  1.65it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 148/160 [02:41<00:06,  1.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 149/160 [02:42<00:04,  2.28it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:42<00:03,  2.57it/s]                                                 {'loss': 0.1731, 'learning_rate': 6.25e-07, 'epoch': 4.69}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:42<00:03,  2.57it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.2648662030696869, 'eval_accuracy': 0.906, 'eval_runtime': 2.6453, 'eval_samples_per_second': 378.024, 'epoch': 4.69}

                                             [A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:45<00:03,  2.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/160 [02:51<00:25,  2.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 152/160 [02:51<00:16,  2.10s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/160 [02:51<00:10,  1.55s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/160 [02:51<00:07,  1.17s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 155/160 [02:52<00:04,  1.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 156/160 [02:52<00:02,  1.40it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 157/160 [02:52<00:01,  1.71it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 158/160 [02:52<00:00,  2.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 159/160 [02:53<00:00,  2.34it/s]                                                 {'loss': 0.1636, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:53<00:00,  2.34it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.07it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 {'eval_loss': 0.26196324825286865, 'eval_accuracy': 0.906, 'eval_runtime': 2.6478, 'eval_samples_per_second': 377.666, 'epoch': 5.0}
                                             [A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:56<00:00,  2.34it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A                                                 {'train_runtime': 187.638, 'train_samples_per_second': 0.853, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:05<00:00,  2.34it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [33]                   : (0.31, 5.0)
COMET INFO:     eval_accuracy [16]           : (0.548, 0.906)
COMET INFO:     eval_loss [16]               : (0.260446161031723, 1.241909146308899)
COMET INFO:     eval_runtime [16]            : (2.6219, 2.6502)
COMET INFO:     eval_samples_per_second [16] : (377.337, 381.397)
COMET INFO:     learning_rate [16]           : (0.0, 9.375000000000001e-06)
COMET INFO:     loss [32]                    : (0.12743112444877625, 1.3992764949798584)
COMET INFO:     total_flos                   : 2731876085760000
COMET INFO:     train_runtime                : 187.638
COMET INFO:     train_samples_per_second     : 0.853
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp2aq0ll9z/7d0f172ecd9c4d1a94b6931e25cde1da.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:07<00:00,  1.17s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.80it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.50it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s]{'eval_loss': 0.2648662030696869, 'eval_accuracy': 0.906, 'eval_runtime': 2.6834, 'eval_samples_per_second': 372.668, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.906
COMET INFO:     eval_loss               : 0.2648662030696869
COMET INFO:     eval_runtime            : 2.6834
COMET INFO:     eval_samples_per_second : 372.668
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpdqfakfi1/67e7b7dca1a3407293c8c7f88b4596c9.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<01:20,  1.02s/it]  2%|â–Ž         | 2/80 [00:01<01:08,  1.15it/s]  4%|â–         | 3/80 [00:02<00:59,  1.30it/s]  5%|â–Œ         | 4/80 [00:02<00:53,  1.43it/s]  6%|â–‹         | 5/80 [00:03<00:48,  1.54it/s]  8%|â–Š         | 6/80 [00:03<00:45,  1.62it/s]  9%|â–‰         | 7/80 [00:04<00:43,  1.69it/s] 10%|â–ˆ         | 8/80 [00:04<00:41,  1.74it/s] 11%|â–ˆâ–        | 9/80 [00:05<00:40,  1.77it/s] 12%|â–ˆâ–Ž        | 10/80 [00:05<00:38,  1.80it/s]                                               {'loss': 1.3151, 'learning_rate': 8.750000000000001e-06, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:05<00:38,  1.80it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.14it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.67it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                               
                                             [A{'eval_loss': 1.1939557790756226, 'eval_accuracy': 0.625, 'eval_runtime': 2.6333, 'eval_samples_per_second': 379.75, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:08<00:38,  1.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 14%|â–ˆâ–        | 11/80 [00:15<03:36,  3.14s/it] 15%|â–ˆâ–Œ        | 12/80 [00:15<02:40,  2.36s/it] 16%|â–ˆâ–‹        | 13/80 [00:16<02:01,  1.81s/it] 18%|â–ˆâ–Š        | 14/80 [00:16<01:34,  1.43s/it] 19%|â–ˆâ–‰        | 15/80 [00:17<01:15,  1.16s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:17<00:58,  1.09it/s] 21%|â–ˆâ–ˆâ–       | 17/80 [00:18<00:50,  1.24it/s] 22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:18<00:45,  1.38it/s] 24%|â–ˆâ–ˆâ–       | 19/80 [00:19<00:40,  1.49it/s] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:38,  1.58it/s]                                               {'loss': 1.1106, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:38,  1.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             {'eval_loss': 0.9465445280075073, 'eval_accuracy': 0.686, 'eval_runtime': 2.6409, 'eval_samples_per_second': 378.652, 'epoch': 1.25}[A
 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:22<00:38,  1.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:29<03:12,  3.26s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:29<02:21,  2.45s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:30<01:46,  1.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:30<01:22,  1.48s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:31<01:05,  1.19s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/80 [00:31<00:53,  1.00it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:32<00:45,  1.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:32<00:39,  1.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:33<00:35,  1.43it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:33<00:32,  1.53it/s]                                               {'loss': 0.8477, 'learning_rate': 6.25e-06, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:33<00:32,  1.53it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             [A{'eval_loss': 0.7062740325927734, 'eval_accuracy': 0.792, 'eval_runtime': 2.6411, 'eval_samples_per_second': 378.63, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:36<00:32,  1.53it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:43<02:39,  3.26s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:43<01:54,  2.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:44<01:26,  1.84s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/80 [00:44<01:06,  1.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:45<00:52,  1.18s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:45<00:43,  1.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:46<00:36,  1.17it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [00:46<00:31,  1.31it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [00:47<00:28,  1.44it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:48<00:26,  1.54it/s]                                               {'loss': 0.6972, 'learning_rate': 5e-06, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:48<00:26,  1.54it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.5673438906669617, 'eval_accuracy': 0.85, 'eval_runtime': 2.6445, 'eval_samples_per_second': 378.149, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:50<00:26,  1.54it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [00:57<02:06,  3.24s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/80 [00:57<01:32,  2.43s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [00:58<01:08,  1.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [00:58<00:52,  1.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [00:59<00:41,  1.19s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:00<00:33,  1.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:00<00:28,  1.16it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:00<00:22,  1.41it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:01<00:20,  1.52it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:02<00:18,  1.60it/s]                                               {'loss': 0.5382, 'learning_rate': 3.7500000000000005e-06, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:02<00:18,  1.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.48059433698654175, 'eval_accuracy': 0.872, 'eval_runtime': 2.6496, 'eval_samples_per_second': 377.421, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:04<00:18,  1.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:11<01:31,  3.17s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:11<01:06,  2.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:12<00:49,  1.82s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:12<00:37,  1.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:13<00:29,  1.17s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:13<00:23,  1.02it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:14<00:19,  1.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/80 [01:14<00:16,  1.33it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:15<00:14,  1.46it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:15<00:12,  1.56it/s]                                               {'loss': 0.4497, 'learning_rate': 2.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:15<00:12,  1.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.11it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.4219388961791992, 'eval_accuracy': 0.875, 'eval_runtime': 2.6523, 'eval_samples_per_second': 377.032, 'epoch': 3.75}
                                             [A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:18<00:12,  1.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:25<01:00,  3.18s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:25<00:42,  2.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:26<00:31,  1.83s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:26<00:22,  1.39s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:26<00:17,  1.13s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [01:27<00:13,  1.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:28<00:10,  1.20it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:28<00:08,  1.34it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:29<00:07,  1.46it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:29<00:06,  1.56it/s]                                               {'loss': 0.3775, 'learning_rate': 1.25e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:29<00:06,  1.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
{'eval_loss': 0.38924795389175415, 'eval_accuracy': 0.883, 'eval_runtime': 2.6608, 'eval_samples_per_second': 375.833, 'epoch': 4.38}                                             [A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:32<00:06,  1.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:38<00:28,  3.19s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:39<00:19,  2.39s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:39<00:12,  1.84s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/80 [01:40<00:08,  1.45s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [01:40<00:05,  1.17s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [01:41<00:03,  1.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [01:42<00:02,  1.17it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [01:42<00:01,  1.32it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [01:43<00:00,  1.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:43<00:00,  1.69it/s]                                               {'loss': 0.3621, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:43<00:00,  1.69it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               {'eval_loss': 0.37932848930358887, 'eval_accuracy': 0.885, 'eval_runtime': 2.6594, 'eval_samples_per_second': 376.03, 'epoch': 5.0}
                                             [A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:46<00:00,  1.69it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A                                               {'train_runtime': 118.1892, 'train_samples_per_second': 0.677, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:56<00:00,  1.69it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [17]                  : (0.62, 5.0)
COMET INFO:     eval_accuracy [8]           : (0.625, 0.885)
COMET INFO:     eval_loss [8]               : (0.37932848930358887, 1.1939557790756226)
COMET INFO:     eval_runtime [8]            : (2.6333, 2.6608)
COMET INFO:     eval_samples_per_second [8] : (375.833, 379.75)
COMET INFO:     learning_rate [8]           : (0.0, 8.750000000000001e-06)
COMET INFO:     loss [24]                   : (0.1375163197517395, 1.3151)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 118.1892
COMET INFO:     train_samples_per_second    : 0.677
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp5rw1bng7/df59c2f4fdd94176880e03bebcf7fbc6.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:57<00:00,  1.47s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.44it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.83it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.51it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.62it/s]{'eval_loss': 0.37932848930358887, 'eval_accuracy': 0.885, 'eval_runtime': 2.6881, 'eval_samples_per_second': 372.006, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.885
COMET INFO:     eval_loss               : 0.37932848930358887
COMET INFO:     eval_runtime            : 2.6881
COMET INFO:     eval_samples_per_second : 372.006
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpe4nyq4u1/5bb9bafcb3ac47cfb6de987755b481f0.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/40 [00:00<?, ?it/s]  2%|â–Ž         | 1/40 [00:01<01:01,  1.57s/it]  5%|â–Œ         | 2/40 [00:02<00:53,  1.41s/it]  8%|â–Š         | 3/40 [00:03<00:48,  1.30s/it] 10%|â–ˆ         | 4/40 [00:04<00:44,  1.23s/it] 12%|â–ˆâ–Ž        | 5/40 [00:05<00:41,  1.17s/it] 15%|â–ˆâ–Œ        | 6/40 [00:06<00:38,  1.14s/it] 18%|â–ˆâ–Š        | 7/40 [00:07<00:36,  1.11s/it] 20%|â–ˆâ–ˆ        | 8/40 [00:08<00:33,  1.04s/it] 22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:09<00:32,  1.04s/it] 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.05s/it]                                               {'loss': 1.3027, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.05s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.10it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.64it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 1.1680800914764404, 'eval_accuracy': 0.627, 'eval_runtime': 2.6528, 'eval_samples_per_second': 376.962, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:13<00:31,  1.05s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 28%|â–ˆâ–ˆâ–Š       | 11/40 [00:20<01:46,  3.66s/it] 30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:21<01:20,  2.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:22<01:02,  2.33s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:23<00:50,  1.94s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:24<00:41,  1.67s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:34,  1.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:30,  1.32s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:27,  1.24s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:28<00:24,  1.18s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:22,  1.14s/it]                                               {'loss': 1.0818, 'learning_rate': 5e-06, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:22,  1.14s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
                                             [A{'eval_loss': 0.9298344254493713, 'eval_accuracy': 0.775, 'eval_runtime': 2.6586, 'eval_samples_per_second': 376.132, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:32<00:22,  1.14s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:39<01:11,  3.74s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:40<00:52,  2.93s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:41<00:40,  2.37s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:42<00:30,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:43<00:24,  1.66s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:44<00:20,  1.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:45<00:17,  1.35s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:46<00:15,  1.26s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:47<00:13,  1.20s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:48<00:11,  1.15s/it]{'loss': 0.8553, 'learning_rate': 2.5e-06, 'epoch': 3.75}
                                                75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:48<00:11,  1.15s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.98it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.57it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.91it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.56it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                               {'eval_loss': 0.7565077543258667, 'eval_accuracy': 0.786, 'eval_runtime': 2.664, 'eval_samples_per_second': 375.378, 'epoch': 3.75}
                                             [A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:51<00:11,  1.15s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:58<00:33,  3.69s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:59<00:22,  2.84s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [01:00<00:16,  2.31s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [01:01<00:11,  1.94s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [01:02<00:08,  1.68s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [01:03<00:05,  1.50s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [01:04<00:04,  1.37s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [01:05<00:02,  1.28s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [01:06<00:01,  1.22s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:07<00:00,  1.12s/it]                                               {'loss': 0.7632, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:07<00:00,  1.12s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.96it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.56it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.91it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.56it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.35it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                               
                                             {'eval_loss': 0.709731936454773, 'eval_accuracy': 0.812, 'eval_runtime': 2.6697, 'eval_samples_per_second': 374.577, 'epoch': 5.0}[A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:10<00:00,  1.12s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A                                               {'train_runtime': 85.0042, 'train_samples_per_second': 0.471, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:23<00:00,  1.12s/it]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [9]                   : (1.25, 5.0)
COMET INFO:     eval_accuracy [4]           : (0.627, 0.812)
COMET INFO:     eval_loss [4]               : (0.709731936454773, 1.1680800914764404)
COMET INFO:     eval_runtime [4]            : (2.6528, 2.6697)
COMET INFO:     eval_samples_per_second [4] : (374.577, 376.962)
COMET INFO:     learning_rate [4]           : (0.0, 7.500000000000001e-06)
COMET INFO:     loss [20]                   : (0.17311713099479675, 1.3027)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 85.0042
COMET INFO:     train_samples_per_second    : 0.471
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpwzv9b8y9/48383b3e278f431ba6769a12a549ac29.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:25<00:00,  2.14s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.24it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.76it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.48it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.51it/s]{'eval_loss': 0.709731936454773, 'eval_accuracy': 0.812, 'eval_runtime': 2.7007, 'eval_samples_per_second': 370.277, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.812
COMET INFO:     eval_loss               : 0.709731936454773
COMET INFO:     eval_runtime            : 2.7007
COMET INFO:     eval_samples_per_second : 370.277
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp3ju1zvy4/e74366c77e5d482ea87f88ff857eb8ee.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/160 [00:00<?, ?it/s]  1%|          | 1/160 [00:00<02:04,  1.28it/s]  1%|â–         | 2/160 [00:01<01:39,  1.58it/s]  2%|â–         | 3/160 [00:01<01:22,  1.91it/s]  2%|â–Ž         | 4/160 [00:01<01:10,  2.22it/s]  3%|â–Ž         | 5/160 [00:01<01:02,  2.50it/s]  4%|â–         | 6/160 [00:02<00:55,  2.75it/s]  4%|â–         | 7/160 [00:02<00:51,  2.97it/s]  5%|â–Œ         | 8/160 [00:02<00:48,  3.13it/s]  6%|â–Œ         | 9/160 [00:03<00:46,  3.25it/s]  6%|â–‹         | 10/160 [00:03<00:44,  3.35it/s]                                                {'loss': 1.2811, 'learning_rate': 2.8125e-05, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:03<00:44,  3.35it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.13it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.66it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                
                                             [A{'eval_loss': 1.0492944717407227, 'eval_accuracy': 0.542, 'eval_runtime': 2.6396, 'eval_samples_per_second': 378.84, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:05<00:44,  3.35it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A  7%|â–‹         | 11/160 [00:12<07:11,  2.90s/it]  8%|â–Š         | 12/160 [00:12<05:12,  2.11s/it]  8%|â–Š         | 13/160 [00:12<03:49,  1.56s/it]  9%|â–‰         | 14/160 [00:13<02:51,  1.18s/it]  9%|â–‰         | 15/160 [00:13<02:11,  1.10it/s] 10%|â–ˆ         | 16/160 [00:13<01:43,  1.39it/s] 11%|â–ˆ         | 17/160 [00:13<01:23,  1.71it/s] 11%|â–ˆâ–        | 18/160 [00:14<01:10,  2.03it/s] 12%|â–ˆâ–        | 19/160 [00:14<01:00,  2.33it/s] 12%|â–ˆâ–Ž        | 20/160 [00:14<00:53,  2.60it/s]                                                {'loss': 0.8965, 'learning_rate': 2.625e-05, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:14<00:53,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.6759741306304932, 'eval_accuracy': 0.766, 'eval_runtime': 2.6406, 'eval_samples_per_second': 378.699, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:17<00:53,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 13%|â–ˆâ–Ž        | 21/160 [00:23<06:47,  2.93s/it] 14%|â–ˆâ–        | 22/160 [00:23<04:54,  2.14s/it] 14%|â–ˆâ–        | 23/160 [00:24<03:36,  1.58s/it] 15%|â–ˆâ–Œ        | 24/160 [00:24<02:41,  1.19s/it] 16%|â–ˆâ–Œ        | 25/160 [00:24<02:03,  1.09it/s] 16%|â–ˆâ–‹        | 26/160 [00:25<01:37,  1.38it/s] 17%|â–ˆâ–‹        | 27/160 [00:25<01:18,  1.69it/s] 18%|â–ˆâ–Š        | 28/160 [00:25<01:05,  2.01it/s] 18%|â–ˆâ–Š        | 29/160 [00:25<00:56,  2.31it/s] 19%|â–ˆâ–‰        | 30/160 [00:26<00:50,  2.59it/s]                                                {'loss': 0.5535, 'learning_rate': 2.4375e-05, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:26<00:50,  2.59it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.3671678602695465, 'eval_accuracy': 0.875, 'eval_runtime': 2.6431, 'eval_samples_per_second': 378.342, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:28<00:50,  2.59it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 19%|â–ˆâ–‰        | 31/160 [00:36<07:32,  3.51s/it] 21%|â–ˆâ–ˆ        | 33/160 [00:37<05:18,  2.51s/it] 21%|â–ˆâ–ˆâ–       | 34/160 [00:37<03:51,  1.84s/it] 22%|â–ˆâ–ˆâ–       | 35/160 [00:37<02:51,  1.37s/it] 22%|â–ˆâ–ˆâ–Ž       | 36/160 [00:38<02:09,  1.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 37/160 [00:38<01:40,  1.23it/s] 24%|â–ˆâ–ˆâ–       | 38/160 [00:38<01:19,  1.53it/s] 24%|â–ˆâ–ˆâ–       | 39/160 [00:38<01:05,  1.85it/s] 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:39<00:55,  2.17it/s]                                                {'loss': 0.2951, 'learning_rate': 2.25e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:39<00:55,  2.17it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.3589385151863098, 'eval_accuracy': 0.87, 'eval_runtime': 2.6404, 'eval_samples_per_second': 378.725, 'epoch': 1.25} 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:41<00:55,  2.17it/s]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–Œ       | 41/160 [00:48<06:04,  3.06s/it] 26%|â–ˆâ–ˆâ–‹       | 42/160 [00:48<04:22,  2.23s/it] 27%|â–ˆâ–ˆâ–‹       | 43/160 [00:48<03:12,  1.64s/it] 28%|â–ˆâ–ˆâ–Š       | 44/160 [00:49<02:23,  1.24s/it] 28%|â–ˆâ–ˆâ–Š       | 45/160 [00:49<01:49,  1.05it/s] 29%|â–ˆâ–ˆâ–‰       | 46/160 [00:49<01:25,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 47/160 [00:50<01:08,  1.64it/s] 30%|â–ˆâ–ˆâ–ˆ       | 48/160 [00:50<00:57,  1.96it/s] 31%|â–ˆâ–ˆâ–ˆ       | 49/160 [00:50<00:49,  2.26it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:50<00:43,  2.53it/s]                                                {'loss': 0.2356, 'learning_rate': 2.0625e-05, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:50<00:43,  2.53it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.3064653277397156, 'eval_accuracy': 0.885, 'eval_runtime': 2.6441, 'eval_samples_per_second': 378.198, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:53<00:43,  2.53it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 32%|â–ˆâ–ˆâ–ˆâ–      | 51/160 [00:59<05:19,  2.93s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/160 [01:00<03:50,  2.13s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/160 [01:00<02:48,  1.58s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 54/160 [01:00<02:05,  1.19s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 55/160 [01:00<01:35,  1.10it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/160 [01:01<01:15,  1.39it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 57/160 [01:01<01:00,  1.70it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 58/160 [01:01<00:50,  2.01it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 59/160 [01:01<00:43,  2.31it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:02<00:38,  2.58it/s]                                                {'loss': 0.2777, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:02<00:38,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                
                                             [A{'eval_loss': 0.2729763090610504, 'eval_accuracy': 0.902, 'eval_runtime': 2.6454, 'eval_samples_per_second': 378.011, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:04<00:38,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 61/160 [01:11<04:53,  2.96s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 62/160 [01:11<03:31,  2.16s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 63/160 [01:11<02:34,  1.59s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 65/160 [01:12<01:51,  1.17s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/160 [01:12<01:24,  1.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/160 [01:12<01:06,  1.40it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/160 [01:12<00:53,  1.72it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 69/160 [01:13<00:44,  2.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:13<00:38,  2.35it/s]                                                {'loss': 0.1534, 'learning_rate': 1.6875e-05, 'epoch': 2.19}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:13<00:38,  2.35it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.20393626391887665, 'eval_accuracy': 0.921, 'eval_runtime': 2.6415, 'eval_samples_per_second': 378.566, 'epoch': 2.19}

                                             [A 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:16<00:38,  2.35it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 71/160 [01:22<04:22,  2.95s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/160 [01:22<03:09,  2.15s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 73/160 [01:22<02:18,  1.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/160 [01:23<01:42,  1.19s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 75/160 [01:23<01:18,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/160 [01:23<01:00,  1.38it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 77/160 [01:24<00:49,  1.69it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 78/160 [01:24<00:40,  2.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 79/160 [01:24<00:34,  2.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:24<00:30,  2.60it/s]                                                {'loss': 0.1081, 'learning_rate': 1.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:24<00:30,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.16862857341766357, 'eval_accuracy': 0.941, 'eval_runtime': 2.6431, 'eval_samples_per_second': 378.346, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:27<00:30,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 81/160 [01:33<03:54,  2.97s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/160 [01:34<02:48,  2.16s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 83/160 [01:34<02:03,  1.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 84/160 [01:34<01:31,  1.20s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 85/160 [01:34<01:09,  1.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 86/160 [01:35<00:54,  1.37it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 87/160 [01:35<00:43,  1.67it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 88/160 [01:35<00:36,  1.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 89/160 [01:36<00:30,  2.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:36<00:27,  2.58it/s]                                                {'loss': 0.1022, 'learning_rate': 1.3125e-05, 'epoch': 2.81}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:36<00:27,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.17101748287677765, 'eval_accuracy': 0.939, 'eval_runtime': 2.6683, 'eval_samples_per_second': 374.769, 'epoch': 2.81}

                                             [A 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:39<00:27,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 91/160 [01:46<03:52,  3.37s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 92/160 [01:46<02:46,  2.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 93/160 [01:47<02:00,  1.80s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 94/160 [01:47<01:28,  1.34s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 95/160 [01:47<01:06,  1.02s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 97/160 [01:48<00:48,  1.29it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 98/160 [01:48<00:38,  1.60it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 99/160 [01:48<00:31,  1.93it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:49<00:26,  2.24it/s]                                                 {'loss': 0.0499, 'learning_rate': 1.125e-05, 'epoch': 3.12} 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:49<00:26,  2.24it/s]

  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             [A{'eval_loss': 0.19825506210327148, 'eval_accuracy': 0.933, 'eval_runtime': 2.6451, 'eval_samples_per_second': 378.057, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:51<00:26,  2.24it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 101/160 [02:00<03:32,  3.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/160 [02:00<02:31,  2.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 103/160 [02:00<01:48,  1.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 104/160 [02:00<01:19,  1.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 105/160 [02:01<00:59,  1.08s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 106/160 [02:01<00:45,  1.19it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 107/160 [02:01<00:35,  1.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 108/160 [02:01<00:28,  1.81it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 109/160 [02:02<00:23,  2.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [02:02<00:20,  2.42it/s]                                                 {'loss': 0.0286, 'learning_rate': 9.375000000000001e-06, 'epoch': 3.44}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [02:02<00:20,  2.42it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 {'eval_loss': 0.1920037716627121, 'eval_accuracy': 0.937, 'eval_runtime': 2.6448, 'eval_samples_per_second': 378.107, 'epoch': 3.44}
                                             [A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [02:05<00:20,  2.42it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 111/160 [02:11<02:27,  3.02s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 112/160 [02:11<01:45,  2.19s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 113/160 [02:12<01:16,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 114/160 [02:12<00:55,  1.22s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 115/160 [02:12<00:42,  1.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 116/160 [02:13<00:32,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 117/160 [02:13<00:25,  1.66it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/160 [02:13<00:21,  1.98it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 119/160 [02:13<00:17,  2.28it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:14<00:15,  2.55it/s]                                                 {'loss': 0.05, 'learning_rate': 7.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:14<00:15,  2.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             [A{'eval_loss': 0.23056073486804962, 'eval_accuracy': 0.927, 'eval_runtime': 2.6413, 'eval_samples_per_second': 378.598, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:16<00:15,  2.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 121/160 [02:24<02:08,  3.29s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 122/160 [02:24<01:30,  2.39s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 123/160 [02:24<01:04,  1.76s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 124/160 [02:25<00:47,  1.31s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 125/160 [02:25<00:35,  1.00s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 126/160 [02:25<00:26,  1.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 127/160 [02:25<00:20,  1.58it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 129/160 [02:26<00:15,  2.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:26<00:12,  2.32it/s]                                                 {'loss': 0.019, 'learning_rate': 5.625e-06, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:26<00:12,  2.32it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             [A{'eval_loss': 0.20242008566856384, 'eval_accuracy': 0.941, 'eval_runtime': 2.6441, 'eval_samples_per_second': 378.205, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:29<00:12,  2.32it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/160 [02:36<01:39,  3.43s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 132/160 [02:37<01:09,  2.48s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 133/160 [02:37<00:49,  1.82s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/160 [02:37<00:35,  1.36s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 135/160 [02:38<00:25,  1.03s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 136/160 [02:38<00:19,  1.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 137/160 [02:38<00:14,  1.54it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 138/160 [02:38<00:11,  1.85it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 139/160 [02:39<00:09,  2.16it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:39<00:08,  2.45it/s]                                                 {'loss': 0.0084, 'learning_rate': 3.75e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:39<00:08,  2.45it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             [A{'eval_loss': 0.2069849669933319, 'eval_accuracy': 0.941, 'eval_runtime': 2.6446, 'eval_samples_per_second': 378.129, 'epoch': 4.38} 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:42<00:08,  2.45it/s]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 141/160 [02:48<00:56,  2.98s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 142/160 [02:48<00:39,  2.17s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 143/160 [02:48<00:27,  1.60s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 144/160 [02:49<00:19,  1.21s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 145/160 [02:49<00:13,  1.08it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 146/160 [02:49<00:10,  1.36it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/160 [02:50<00:07,  1.67it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 148/160 [02:50<00:06,  1.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 149/160 [02:50<00:04,  2.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:50<00:03,  2.57it/s]                                                 {'loss': 0.0126, 'learning_rate': 1.875e-06, 'epoch': 4.69}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:50<00:03,  2.57it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 {'eval_loss': 0.22200611233711243, 'eval_accuracy': 0.939, 'eval_runtime': 2.6445, 'eval_samples_per_second': 378.15, 'epoch': 4.69}
                                             [A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:53<00:03,  2.57it/s]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/160 [02:59<00:26,  2.96s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 152/160 [03:00<00:17,  2.15s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/160 [03:00<00:11,  1.59s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/160 [03:00<00:07,  1.20s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 155/160 [03:01<00:04,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 156/160 [03:01<00:02,  1.37it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 157/160 [03:01<00:01,  1.68it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 158/160 [03:01<00:01,  2.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 159/160 [03:02<00:00,  2.30it/s]                                                 {'loss': 0.0227, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:02<00:00,  2.30it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             [A{'eval_loss': 0.21757808327674866, 'eval_accuracy': 0.939, 'eval_runtime': 2.6442, 'eval_samples_per_second': 378.181, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:04<00:00,  2.30it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A                                                 {'train_runtime': 196.3196, 'train_samples_per_second': 0.815, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:14<00:00,  2.30it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [33]                   : (0.31, 5.0)
COMET INFO:     eval_accuracy [16]           : (0.542, 0.941)
COMET INFO:     eval_loss [16]               : (0.16862857341766357, 1.0492944717407227)
COMET INFO:     eval_runtime [16]            : (2.6396, 2.6683)
COMET INFO:     eval_samples_per_second [16] : (374.769, 378.84)
COMET INFO:     learning_rate [16]           : (0.0, 2.8125e-05)
COMET INFO:     loss [32]                    : (0.0084, 1.3992764949798584)
COMET INFO:     total_flos                   : 2731876085760000
COMET INFO:     train_runtime                : 196.3196
COMET INFO:     train_samples_per_second     : 0.815
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp20fpz2wp/8f8b1ab3fe6a4b9a8a415606e9bcf6df.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:17<00:00,  1.23s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.74it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.47it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.62it/s]{'eval_loss': 0.16862857341766357, 'eval_accuracy': 0.941, 'eval_runtime': 2.7004, 'eval_samples_per_second': 370.309, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.941
COMET INFO:     eval_loss               : 0.16862857341766357
COMET INFO:     eval_runtime            : 2.7004
COMET INFO:     eval_samples_per_second : 370.309
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpwfa3_qwf/48331939d8f64e81af0c592ea910f468.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<01:21,  1.03s/it]  2%|â–Ž         | 2/80 [00:01<01:08,  1.13it/s]  4%|â–         | 3/80 [00:02<01:00,  1.28it/s]  5%|â–Œ         | 4/80 [00:02<00:53,  1.42it/s]  6%|â–‹         | 5/80 [00:03<00:48,  1.53it/s]  8%|â–Š         | 6/80 [00:03<00:45,  1.62it/s]  9%|â–‰         | 7/80 [00:04<00:43,  1.69it/s] 10%|â–ˆ         | 8/80 [00:04<00:41,  1.75it/s] 11%|â–ˆâ–        | 9/80 [00:05<00:39,  1.78it/s] 12%|â–ˆâ–Ž        | 10/80 [00:05<00:38,  1.81it/s]                                               {'loss': 1.2048, 'learning_rate': 2.625e-05, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:05<00:38,  1.81it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.14it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.67it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s][A                                               
                                             [A{'eval_loss': 0.8223016858100891, 'eval_accuracy': 0.766, 'eval_runtime': 2.6326, 'eval_samples_per_second': 379.845, 'epoch': 0.62} 12%|â–ˆâ–Ž        | 10/80 [00:08<00:38,  1.81it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s][A

                                             [A 14%|â–ˆâ–        | 11/80 [00:15<03:36,  3.14s/it] 15%|â–ˆâ–Œ        | 12/80 [00:15<02:40,  2.36s/it] 16%|â–ˆâ–‹        | 13/80 [00:16<02:01,  1.81s/it] 18%|â–ˆâ–Š        | 14/80 [00:16<01:34,  1.43s/it] 19%|â–ˆâ–‰        | 15/80 [00:17<01:15,  1.16s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:17<00:58,  1.09it/s] 21%|â–ˆâ–ˆâ–       | 17/80 [00:18<00:50,  1.24it/s] 22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:18<00:44,  1.39it/s] 24%|â–ˆâ–ˆâ–       | 19/80 [00:19<00:40,  1.50it/s] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:37,  1.60it/s]                                               {'loss': 0.6687, 'learning_rate': 2.25e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:37,  1.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               {'eval_loss': 0.4546308219432831, 'eval_accuracy': 0.848, 'eval_runtime': 2.6391, 'eval_samples_per_second': 378.914, 'epoch': 1.25}

                                             [A 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:22<00:37,  1.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:29<03:21,  3.41s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:30<02:27,  2.55s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:30<01:50,  1.94s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:31<01:25,  1.52s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:31<01:07,  1.23s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/80 [00:32<00:55,  1.02s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:32<00:46,  1.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:33<00:40,  1.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:33<00:35,  1.43it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:34<00:32,  1.54it/s]                                               {'loss': 0.3764, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:34<00:32,  1.54it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                               {'eval_loss': 0.3276154696941376, 'eval_accuracy': 0.886, 'eval_runtime': 2.6551, 'eval_samples_per_second': 376.628, 'epoch': 1.88}
                                             [A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:37<00:32,  1.54it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:44<02:44,  3.35s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:44<01:57,  2.45s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:44<01:28,  1.88s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/80 [00:45<01:07,  1.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:45<00:53,  1.19s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:46<00:43,  1.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:47<00:36,  1.17it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [00:47<00:31,  1.31it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [00:48<00:28,  1.44it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:48<00:25,  1.55it/s]                                               {'loss': 0.2559, 'learning_rate': 1.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:48<00:25,  1.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.24829727411270142, 'eval_accuracy': 0.917, 'eval_runtime': 2.6466, 'eval_samples_per_second': 377.845, 'epoch': 2.5}

                                             [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:51<00:25,  1.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [00:58<02:09,  3.32s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/80 [00:58<01:34,  2.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [00:59<01:10,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [00:59<00:53,  1.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:00<00:42,  1.20s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:00<00:34,  1.00s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:01<00:28,  1.16it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:01<00:22,  1.42it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:02<00:20,  1.53it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:02<00:18,  1.62it/s]                                               {'loss': 0.1735, 'learning_rate': 1.125e-05, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:02<00:18,  1.62it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.22099822759628296, 'eval_accuracy': 0.918, 'eval_runtime': 2.6503, 'eval_samples_per_second': 377.318, 'epoch': 3.12}
                                             [A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:05<00:18,  1.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:12<01:34,  3.24s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:12<01:08,  2.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:13<00:50,  1.87s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:13<00:38,  1.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:14<00:29,  1.19s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:14<00:23,  1.00it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:15<00:19,  1.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/80 [01:15<00:16,  1.30it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:16<00:14,  1.43it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:17<00:13,  1.53it/s]                                               {'loss': 0.1297, 'learning_rate': 7.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:17<00:13,  1.53it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.22761434316635132, 'eval_accuracy': 0.919, 'eval_runtime': 2.663, 'eval_samples_per_second': 375.516, 'epoch': 3.75}
                                             [A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:19<00:13,  1.53it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:26<01:04,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:27<00:45,  2.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:27<00:33,  1.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:28<00:23,  1.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:28<00:17,  1.19s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [01:29<00:13,  1.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:29<00:11,  1.16it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:30<00:09,  1.31it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:31<00:07,  1.43it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:31<00:06,  1.53it/s]                                               {'loss': 0.088, 'learning_rate': 3.75e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:31<00:06,  1.53it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.20231319963932037, 'eval_accuracy': 0.931, 'eval_runtime': 2.6528, 'eval_samples_per_second': 376.964, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:34<00:06,  1.53it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:41<00:30,  3.34s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:41<00:19,  2.50s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:42<00:13,  1.91s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/80 [01:42<00:09,  1.50s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [01:43<00:06,  1.21s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [01:43<00:04,  1.01s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [01:44<00:02,  1.15it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [01:44<00:01,  1.30it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [01:45<00:00,  1.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:45<00:00,  1.68it/s]                                               {'loss': 0.0795, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:45<00:00,  1.68it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               {'eval_loss': 0.2184886634349823, 'eval_accuracy': 0.924, 'eval_runtime': 2.6511, 'eval_samples_per_second': 377.197, 'epoch': 5.0}
                                             [A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:48<00:00,  1.68it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A                                               {'train_runtime': 123.2487, 'train_samples_per_second': 0.649, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:01<00:00,  1.68it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [17]                  : (0.62, 5.0)
COMET INFO:     eval_accuracy [8]           : (0.766, 0.931)
COMET INFO:     eval_loss [8]               : (0.20231319963932037, 0.8223016858100891)
COMET INFO:     eval_runtime [8]            : (2.6326, 2.663)
COMET INFO:     eval_samples_per_second [8] : (375.516, 379.845)
COMET INFO:     learning_rate [8]           : (0.0, 2.625e-05)
COMET INFO:     loss [24]                   : (0.014638266526162624, 1.2048)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 123.2487
COMET INFO:     train_samples_per_second    : 0.649
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp2p3nkkmg/dd38647ae9af4460af749918638acc71.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:03<00:00,  1.55s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.25it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.77it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.49it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.55it/s]{'eval_loss': 0.20231319963932037, 'eval_accuracy': 0.931, 'eval_runtime': 2.6947, 'eval_samples_per_second': 371.103, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.931
COMET INFO:     eval_loss               : 0.20231319963932037
COMET INFO:     eval_runtime            : 2.6947
COMET INFO:     eval_samples_per_second : 371.103
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpyhxbptgc/52e2bd42af6f4f4599f783a8d354d189.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/40 [00:00<?, ?it/s]  2%|â–Ž         | 1/40 [00:01<01:01,  1.59s/it]  5%|â–Œ         | 2/40 [00:02<00:54,  1.43s/it]  8%|â–Š         | 3/40 [00:03<00:48,  1.32s/it] 10%|â–ˆ         | 4/40 [00:04<00:44,  1.24s/it] 12%|â–ˆâ–Ž        | 5/40 [00:05<00:41,  1.19s/it] 15%|â–ˆâ–Œ        | 6/40 [00:06<00:39,  1.15s/it] 18%|â–ˆâ–Š        | 7/40 [00:07<00:37,  1.13s/it] 20%|â–ˆâ–ˆ        | 8/40 [00:08<00:33,  1.05s/it] 22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:09<00:32,  1.05s/it] 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.06s/it]                                               {'loss': 1.1643, 'learning_rate': 2.25e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:11<00:31,  1.06s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.10it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             {'eval_loss': 0.7866528034210205, 'eval_accuracy': 0.704, 'eval_runtime': 2.6456, 'eval_samples_per_second': 377.982, 'epoch': 1.25}[A
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:13<00:31,  1.06s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 28%|â–ˆâ–ˆâ–Š       | 11/40 [00:20<01:47,  3.71s/it] 30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:21<01:21,  2.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:23<01:03,  2.36s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:24<00:51,  1.97s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:25<00:42,  1.70s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:26<00:34,  1.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:27<00:30,  1.33s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:28<00:27,  1.26s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:25,  1.20s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:23,  1.16s/it]                                               {'loss': 0.59, 'learning_rate': 1.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:23,  1.16s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.4183701276779175, 'eval_accuracy': 0.867, 'eval_runtime': 2.6513, 'eval_samples_per_second': 377.18, 'epoch': 2.5}
                                             [A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:32<00:23,  1.16s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:39<01:10,  3.73s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:41<00:52,  2.93s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:42<00:40,  2.37s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:42<00:30,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:44<00:24,  1.66s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:45<00:20,  1.48s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:46<00:17,  1.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:47<00:15,  1.27s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:48<00:13,  1.21s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:49<00:11,  1.17s/it]                                               {'loss': 0.3068, 'learning_rate': 7.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:49<00:11,  1.17s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.07it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
                                             [A{'eval_loss': 0.3464076817035675, 'eval_accuracy': 0.875, 'eval_runtime': 2.6596, 'eval_samples_per_second': 375.995, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:52<00:11,  1.17s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:59<00:33,  3.75s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [01:00<00:23,  2.88s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [01:01<00:16,  2.34s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [01:02<00:11,  1.96s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [01:03<00:08,  1.69s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [01:04<00:05,  1.50s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [01:05<00:04,  1.37s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [01:06<00:02,  1.28s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [01:07<00:01,  1.21s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:08<00:00,  1.11s/it]                                               {'loss': 0.2448, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:08<00:00,  1.11s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                               
                                             [A{'eval_loss': 0.2664540112018585, 'eval_accuracy': 0.906, 'eval_runtime': 2.6688, 'eval_samples_per_second': 374.706, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:11<00:00,  1.11s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A                                               {'train_runtime': 82.3896, 'train_samples_per_second': 0.485, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:21<00:00,  1.11s/it]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [9]                   : (1.25, 5.0)
COMET INFO:     eval_accuracy [4]           : (0.704, 0.906)
COMET INFO:     eval_loss [4]               : (0.2664540112018585, 0.7866528034210205)
COMET INFO:     eval_runtime [4]            : (2.6456, 2.6688)
COMET INFO:     eval_samples_per_second [4] : (374.706, 377.982)
COMET INFO:     learning_rate [4]           : (0.0, 2.25e-05)
COMET INFO:     loss [20]                   : (0.05228111147880554, 1.1643)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 82.3896
COMET INFO:     train_samples_per_second    : 0.485
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp84u1646b/302ebffbb4584b8ea43e581c660a0131.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:22<00:00,  2.06s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.22it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.75it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.47it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s]{'eval_loss': 0.2664540112018585, 'eval_accuracy': 0.906, 'eval_runtime': 2.7039, 'eval_samples_per_second': 369.841, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.906
COMET INFO:     eval_loss               : 0.2664540112018585
COMET INFO:     eval_runtime            : 2.7039
COMET INFO:     eval_samples_per_second : 369.841
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmprsqcndna/20b0412389194a28a4130e22d0673ca4.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/160 [00:00<?, ?it/s]  1%|          | 1/160 [00:00<02:01,  1.31it/s]  1%|â–         | 2/160 [00:01<01:37,  1.62it/s]  2%|â–         | 3/160 [00:01<01:20,  1.94it/s]  2%|â–Ž         | 4/160 [00:01<01:09,  2.26it/s]  3%|â–Ž         | 5/160 [00:01<01:00,  2.54it/s]  4%|â–         | 6/160 [00:02<00:55,  2.80it/s]  4%|â–         | 7/160 [00:02<00:51,  3.00it/s]  5%|â–Œ         | 8/160 [00:02<00:48,  3.16it/s]  6%|â–Œ         | 9/160 [00:02<00:46,  3.28it/s]  6%|â–‹         | 10/160 [00:03<00:44,  3.37it/s]                                                {'loss': 1.2904, 'learning_rate': 4.6875e-05, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:03<00:44,  3.37it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.19it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.69it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.99it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.41it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                {'eval_loss': 1.0080970525741577, 'eval_accuracy': 0.514, 'eval_runtime': 2.634, 'eval_samples_per_second': 379.644, 'epoch': 0.31}
                                             [A
  6%|â–‹         | 10/160 [00:05<00:44,  3.37it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A  7%|â–‹         | 11/160 [00:12<07:13,  2.91s/it]  8%|â–Š         | 12/160 [00:12<05:13,  2.12s/it]  8%|â–Š         | 13/160 [00:12<03:50,  1.57s/it]  9%|â–‰         | 14/160 [00:13<02:52,  1.18s/it]  9%|â–‰         | 15/160 [00:13<02:12,  1.10it/s] 10%|â–ˆ         | 16/160 [00:13<01:43,  1.39it/s] 11%|â–ˆ         | 17/160 [00:13<01:24,  1.70it/s] 11%|â–ˆâ–        | 18/160 [00:14<01:10,  2.01it/s] 12%|â–ˆâ–        | 19/160 [00:14<01:01,  2.31it/s] 12%|â–ˆâ–Ž        | 20/160 [00:14<00:54,  2.58it/s]                                                {'loss': 0.8315, 'learning_rate': 4.375e-05, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:14<00:54,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.7502540349960327, 'eval_accuracy': 0.686, 'eval_runtime': 2.6415, 'eval_samples_per_second': 378.571, 'epoch': 0.62}

                                             [A 12%|â–ˆâ–Ž        | 20/160 [00:17<00:54,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 13%|â–ˆâ–Ž        | 21/160 [00:23<06:53,  2.98s/it] 14%|â–ˆâ–        | 22/160 [00:24<04:59,  2.17s/it] 14%|â–ˆâ–        | 23/160 [00:24<03:39,  1.60s/it] 15%|â–ˆâ–Œ        | 24/160 [00:24<02:44,  1.21s/it] 16%|â–ˆâ–Œ        | 25/160 [00:24<02:05,  1.08it/s] 16%|â–ˆâ–‹        | 26/160 [00:25<01:38,  1.36it/s] 17%|â–ˆâ–‹        | 27/160 [00:25<01:19,  1.67it/s] 18%|â–ˆâ–Š        | 28/160 [00:25<01:06,  1.98it/s] 18%|â–ˆâ–Š        | 29/160 [00:26<00:57,  2.28it/s] 19%|â–ˆâ–‰        | 30/160 [00:26<00:50,  2.55it/s]                                                {'loss': 0.5469, 'learning_rate': 4.0625000000000005e-05, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:26<00:50,  2.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             {'eval_loss': 0.33264580368995667, 'eval_accuracy': 0.877, 'eval_runtime': 2.6447, 'eval_samples_per_second': 378.114, 'epoch': 0.94}[A
 19%|â–ˆâ–‰        | 30/160 [00:29<00:50,  2.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 19%|â–ˆâ–‰        | 31/160 [00:35<06:21,  2.96s/it] 21%|â–ˆâ–ˆ        | 33/160 [00:35<04:29,  2.13s/it] 21%|â–ˆâ–ˆâ–       | 34/160 [00:35<03:18,  1.57s/it] 22%|â–ˆâ–ˆâ–       | 35/160 [00:36<02:28,  1.19s/it] 22%|â–ˆâ–ˆâ–Ž       | 36/160 [00:36<01:53,  1.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 37/160 [00:36<01:29,  1.38it/s] 24%|â–ˆâ–ˆâ–       | 38/160 [00:37<01:12,  1.69it/s] 24%|â–ˆâ–ˆâ–       | 39/160 [00:37<01:00,  2.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:37<00:51,  2.31it/s]                                                {'loss': 0.2517, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:37<00:51,  2.31it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.2597436010837555, 'eval_accuracy': 0.916, 'eval_runtime': 2.6386, 'eval_samples_per_second': 378.984, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:40<00:51,  2.31it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–Œ       | 41/160 [00:46<05:48,  2.93s/it] 26%|â–ˆâ–ˆâ–‹       | 42/160 [00:46<04:11,  2.13s/it] 27%|â–ˆâ–ˆâ–‹       | 43/160 [00:46<03:04,  1.58s/it] 28%|â–ˆâ–ˆâ–Š       | 44/160 [00:47<02:17,  1.19s/it] 28%|â–ˆâ–ˆâ–Š       | 45/160 [00:47<01:45,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 46/160 [00:47<01:22,  1.38it/s] 29%|â–ˆâ–ˆâ–‰       | 47/160 [00:48<01:06,  1.69it/s] 30%|â–ˆâ–ˆâ–ˆ       | 48/160 [00:48<00:55,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆ       | 49/160 [00:48<00:48,  2.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:48<00:42,  2.58it/s]                                                {'loss': 0.1568, 'learning_rate': 3.4375e-05, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:48<00:42,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                {'eval_loss': 0.2996518015861511, 'eval_accuracy': 0.888, 'eval_runtime': 2.6443, 'eval_samples_per_second': 378.166, 'epoch': 1.56}

                                             [A 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:51<00:42,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 32%|â–ˆâ–ˆâ–ˆâ–      | 51/160 [00:57<05:17,  2.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/160 [00:57<03:49,  2.12s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/160 [00:58<02:48,  1.57s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 54/160 [00:58<02:05,  1.19s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 55/160 [00:58<01:35,  1.10it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/160 [00:59<01:15,  1.38it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 57/160 [00:59<01:00,  1.69it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 58/160 [00:59<00:50,  2.00it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 59/160 [00:59<00:43,  2.31it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:00<00:38,  2.58it/s]                                                {'loss': 0.2869, 'learning_rate': 3.125e-05, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:00<00:38,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.27376043796539307, 'eval_accuracy': 0.898, 'eval_runtime': 2.6453, 'eval_samples_per_second': 378.023, 'epoch': 1.88}

                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:02<00:38,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 61/160 [01:09<04:57,  3.01s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 62/160 [01:09<03:34,  2.19s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 63/160 [01:09<02:36,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 65/160 [01:10<01:52,  1.19s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/160 [01:10<01:25,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/160 [01:10<01:07,  1.39it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/160 [01:11<00:54,  1.70it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 69/160 [01:11<00:45,  2.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:11<00:38,  2.32it/s]                                                {'loss': 0.1352, 'learning_rate': 2.8125000000000003e-05, 'epoch': 2.19}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:11<00:38,  2.32it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.17049838602542877, 'eval_accuracy': 0.943, 'eval_runtime': 2.6467, 'eval_samples_per_second': 377.825, 'epoch': 2.19} 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:14<00:38,  2.32it/s]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 71/160 [01:20<04:23,  2.97s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/160 [01:20<03:10,  2.16s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 73/160 [01:21<02:18,  1.60s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/160 [01:21<01:43,  1.20s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 75/160 [01:21<01:18,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/160 [01:21<01:01,  1.37it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 77/160 [01:22<00:49,  1.68it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 78/160 [01:22<00:41,  1.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 79/160 [01:22<00:35,  2.30it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:23<00:31,  2.57it/s]                                                {'loss': 0.0826, 'learning_rate': 2.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:23<00:31,  2.57it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                
                                             [A{'eval_loss': 0.17211081087589264, 'eval_accuracy': 0.946, 'eval_runtime': 2.6471, 'eval_samples_per_second': 377.777, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:25<00:31,  2.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 81/160 [01:32<04:00,  3.04s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/160 [01:32<02:52,  2.21s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 83/160 [01:32<02:05,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 84/160 [01:33<01:33,  1.23s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 85/160 [01:33<01:10,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 86/160 [01:33<00:54,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 87/160 [01:33<00:43,  1.66it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 88/160 [01:34<00:36,  1.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 89/160 [01:34<00:30,  2.29it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:34<00:27,  2.57it/s]                                                {'loss': 0.0733, 'learning_rate': 2.1875e-05, 'epoch': 2.81}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:34<00:27,  2.57it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.18336234986782074, 'eval_accuracy': 0.942, 'eval_runtime': 2.6487, 'eval_samples_per_second': 377.55, 'epoch': 2.81}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:37<00:27,  2.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 91/160 [01:44<03:38,  3.17s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 92/160 [01:44<02:36,  2.30s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 93/160 [01:45<01:53,  1.69s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 94/160 [01:45<01:23,  1.27s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 95/160 [01:45<01:03,  1.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 97/160 [01:45<00:46,  1.36it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 98/160 [01:46<00:37,  1.67it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 99/160 [01:46<00:30,  1.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:46<00:26,  2.29it/s]                                                 {'loss': 0.0151, 'learning_rate': 1.8750000000000002e-05, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:46<00:26,  2.29it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             {'eval_loss': 0.2374066263437271, 'eval_accuracy': 0.941, 'eval_runtime': 2.6432, 'eval_samples_per_second': 378.333, 'epoch': 3.12}[A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:49<00:26,  2.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 101/160 [01:56<03:04,  3.13s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/160 [01:56<02:12,  2.28s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 103/160 [01:56<01:35,  1.68s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 104/160 [01:57<01:10,  1.26s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 105/160 [01:57<00:52,  1.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 106/160 [01:57<00:40,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 107/160 [01:57<00:32,  1.64it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 108/160 [01:58<00:26,  1.96it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 109/160 [01:58<00:22,  2.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:58<00:19,  2.56it/s]                                                 {'loss': 0.0249, 'learning_rate': 1.5625e-05, 'epoch': 3.44}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:58<00:19,  2.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.242795929312706, 'eval_accuracy': 0.937, 'eval_runtime': 2.6441, 'eval_samples_per_second': 378.207, 'epoch': 3.44}
                                             [A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [02:01<00:19,  2.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 111/160 [02:08<02:33,  3.12s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 112/160 [02:08<01:48,  2.27s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 113/160 [02:08<01:18,  1.67s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 114/160 [02:09<00:57,  1.25s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 115/160 [02:09<00:43,  1.04it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 116/160 [02:09<00:33,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 117/160 [02:09<00:26,  1.64it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/160 [02:10<00:21,  1.96it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 119/160 [02:10<00:18,  2.27it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:10<00:15,  2.56it/s]{'loss': 0.0403, 'learning_rate': 1.25e-05, 'epoch': 3.75}
                                                  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:10<00:15,  2.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.25433820486068726, 'eval_accuracy': 0.934, 'eval_runtime': 2.6485, 'eval_samples_per_second': 377.577, 'epoch': 3.75}

                                             [A 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:13<00:15,  2.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 121/160 [02:19<01:55,  2.97s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 122/160 [02:19<01:22,  2.16s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 123/160 [02:20<00:59,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 124/160 [02:20<00:43,  1.20s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 125/160 [02:20<00:32,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 126/160 [02:21<00:24,  1.36it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 127/160 [02:21<00:19,  1.67it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 129/160 [02:21<00:14,  2.11it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:21<00:12,  2.41it/s]                                                 {'loss': 0.0074, 'learning_rate': 9.375000000000001e-06, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:21<00:12,  2.41it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.23533228039741516, 'eval_accuracy': 0.935, 'eval_runtime': 2.6436, 'eval_samples_per_second': 378.271, 'epoch': 4.06}
                                             [A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:24<00:12,  2.41it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/160 [02:30<01:25,  2.95s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 132/160 [02:31<01:00,  2.15s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 133/160 [02:31<00:42,  1.59s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/160 [02:31<00:31,  1.19s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 135/160 [02:31<00:22,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 136/160 [02:32<00:17,  1.38it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 137/160 [02:32<00:13,  1.69it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 138/160 [02:32<00:10,  2.01it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 139/160 [02:33<00:09,  2.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:33<00:07,  2.61it/s]{'loss': 0.0046, 'learning_rate': 6.25e-06, 'epoch': 4.38}
                                                  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:33<00:07,  2.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.21887506544589996, 'eval_accuracy': 0.946, 'eval_runtime': 2.646, 'eval_samples_per_second': 377.933, 'epoch': 4.38}
                                             [A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:35<00:07,  2.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 141/160 [02:42<00:55,  2.93s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 142/160 [02:42<00:38,  2.13s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 143/160 [02:42<00:26,  1.58s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 144/160 [02:43<00:18,  1.19s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 145/160 [02:43<00:13,  1.10it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 146/160 [02:43<00:10,  1.39it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/160 [02:43<00:07,  1.70it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 148/160 [02:44<00:05,  2.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 149/160 [02:44<00:04,  2.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:44<00:03,  2.62it/s]                                                 {'loss': 0.0026, 'learning_rate': 3.125e-06, 'epoch': 4.69}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:44<00:03,  2.62it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             [A{'eval_loss': 0.24323619902133942, 'eval_accuracy': 0.942, 'eval_runtime': 2.6459, 'eval_samples_per_second': 377.948, 'epoch': 4.69}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:47<00:03,  2.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/160 [02:53<00:26,  2.99s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 152/160 [02:54<00:17,  2.17s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/160 [02:54<00:11,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/160 [02:54<00:07,  1.21s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 155/160 [02:54<00:04,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 156/160 [02:55<00:02,  1.37it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 157/160 [02:55<00:01,  1.68it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 158/160 [02:55<00:00,  2.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 159/160 [02:55<00:00,  2.32it/s]                                                 {'loss': 0.0057, 'learning_rate': 0.0, 'epoch': 5.0}100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:56<00:00,  2.32it/s]

  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.2436220645904541, 'eval_accuracy': 0.942, 'eval_runtime': 2.6474, 'eval_samples_per_second': 377.732, 'epoch': 5.0}

                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:58<00:00,  2.32it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A                                                 {'train_runtime': 189.8495, 'train_samples_per_second': 0.843, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:08<00:00,  2.32it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [33]                   : (0.31, 5.0)
COMET INFO:     eval_accuracy [16]           : (0.514, 0.946)
COMET INFO:     eval_loss [16]               : (0.17049838602542877, 1.0080970525741577)
COMET INFO:     eval_runtime [16]            : (2.634, 2.6487)
COMET INFO:     eval_samples_per_second [16] : (377.55, 379.644)
COMET INFO:     learning_rate [16]           : (0.0, 4.6875e-05)
COMET INFO:     loss [32]                    : (0.0026, 1.3992764949798584)
COMET INFO:     total_flos                   : 2731876085760000
COMET INFO:     train_runtime                : 189.8495
COMET INFO:     train_samples_per_second     : 0.843
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmphvih6f80/57619d98ea1c4fef90e1d367f435589b.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:09<00:00,  1.18s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.29it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.79it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.50it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.63it/s]{'eval_loss': 0.17211081087589264, 'eval_accuracy': 0.946, 'eval_runtime': 2.6857, 'eval_samples_per_second': 372.343, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.946
COMET INFO:     eval_loss               : 0.17211081087589264
COMET INFO:     eval_runtime            : 2.6857
COMET INFO:     eval_samples_per_second : 372.343
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpcvk0ae2d/d51ebfba1a3d40859c2c75f2f0f3c235.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<01:19,  1.01s/it]  2%|â–Ž         | 2/80 [00:01<01:07,  1.15it/s]  4%|â–         | 3/80 [00:02<00:59,  1.30it/s]  5%|â–Œ         | 4/80 [00:02<00:53,  1.43it/s]  6%|â–‹         | 5/80 [00:03<00:48,  1.53it/s]  8%|â–Š         | 6/80 [00:03<00:45,  1.61it/s]  9%|â–‰         | 7/80 [00:04<00:43,  1.68it/s] 10%|â–ˆ         | 8/80 [00:04<00:41,  1.73it/s] 11%|â–ˆâ–        | 9/80 [00:05<00:40,  1.76it/s] 12%|â–ˆâ–Ž        | 10/80 [00:05<00:39,  1.79it/s]                                               {'loss': 1.1667, 'learning_rate': 4.375e-05, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:05<00:39,  1.79it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.13it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.67it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                               
                                             [A{'eval_loss': 0.6785768866539001, 'eval_accuracy': 0.803, 'eval_runtime': 2.6378, 'eval_samples_per_second': 379.11, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:08<00:39,  1.79it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 14%|â–ˆâ–        | 11/80 [00:14<03:35,  3.12s/it] 15%|â–ˆâ–Œ        | 12/80 [00:15<02:39,  2.35s/it] 16%|â–ˆâ–‹        | 13/80 [00:16<02:00,  1.80s/it] 18%|â–ˆâ–Š        | 14/80 [00:16<01:33,  1.42s/it] 19%|â–ˆâ–‰        | 15/80 [00:17<01:15,  1.16s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:17<00:58,  1.09it/s] 21%|â–ˆâ–ˆâ–       | 17/80 [00:18<00:50,  1.25it/s] 22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:18<00:44,  1.38it/s] 24%|â–ˆâ–ˆâ–       | 19/80 [00:19<00:40,  1.49it/s] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:37,  1.59it/s]                                               {'loss': 0.547, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.25} 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:37,  1.59it/s]

  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             {'eval_loss': 0.471047967672348, 'eval_accuracy': 0.824, 'eval_runtime': 2.641, 'eval_samples_per_second': 378.64, 'epoch': 1.25}
[A 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:22<00:37,  1.59it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:28<03:07,  3.18s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:29<02:18,  2.39s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:29<01:44,  1.83s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:30<01:20,  1.44s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:30<01:04,  1.17s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/80 [00:31<00:52,  1.02it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:31<00:44,  1.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:32<00:39,  1.33it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:33<00:34,  1.46it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:33<00:31,  1.56it/s]                                               {'loss': 0.3249, 'learning_rate': 3.125e-05, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:33<00:31,  1.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.3647485375404358, 'eval_accuracy': 0.878, 'eval_runtime': 2.6496, 'eval_samples_per_second': 377.413, 'epoch': 1.88}

                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:36<00:31,  1.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:42<02:35,  3.16s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:42<01:51,  2.32s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:43<01:23,  1.78s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/80 [00:44<01:04,  1.41s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:44<00:51,  1.15s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:45<00:42,  1.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:45<00:35,  1.20it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [00:46<00:31,  1.34it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [00:46<00:27,  1.46it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:47<00:25,  1.57it/s]                                               {'loss': 0.1896, 'learning_rate': 2.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:47<00:25,  1.57it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.2774120569229126, 'eval_accuracy': 0.904, 'eval_runtime': 2.6485, 'eval_samples_per_second': 377.571, 'epoch': 2.5}
                                             [A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:49<00:25,  1.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [00:56<02:04,  3.19s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/80 [00:56<01:30,  2.39s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [00:57<01:07,  1.84s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [00:58<00:52,  1.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [00:58<00:41,  1.17s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [00:59<00:33,  1.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [00:59<00:28,  1.18it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [00:59<00:22,  1.43it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:00<00:20,  1.53it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:01<00:18,  1.61it/s]                                               {'loss': 0.1202, 'learning_rate': 1.8750000000000002e-05, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:01<00:18,  1.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.18942925333976746, 'eval_accuracy': 0.934, 'eval_runtime': 2.656, 'eval_samples_per_second': 376.505, 'epoch': 3.12}
                                             [A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:03<00:18,  1.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:10<01:32,  3.18s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:10<01:06,  2.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:11<00:49,  1.83s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:11<00:37,  1.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:12<00:29,  1.17s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:12<00:23,  1.02it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:13<00:19,  1.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/80 [01:13<00:16,  1.32it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:14<00:14,  1.45it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:15<00:12,  1.55it/s]                                               {'loss': 0.0604, 'learning_rate': 1.25e-05, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:15<00:12,  1.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.21485134959220886, 'eval_accuracy': 0.93, 'eval_runtime': 2.6526, 'eval_samples_per_second': 376.988, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:17<00:12,  1.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:24<00:59,  3.14s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:24<00:42,  2.36s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:25<00:30,  1.81s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:25<00:21,  1.37s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:25<00:16,  1.13s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [01:26<00:13,  1.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:27<00:10,  1.21it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:27<00:08,  1.35it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:28<00:07,  1.47it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:28<00:06,  1.56it/s]                                               {'loss': 0.0347, 'learning_rate': 6.25e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:28<00:06,  1.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.19100379943847656, 'eval_accuracy': 0.934, 'eval_runtime': 2.653, 'eval_samples_per_second': 376.938, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:31<00:06,  1.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:37<00:28,  3.21s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:38<00:19,  2.41s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:38<00:12,  1.84s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/80 [01:39<00:08,  1.45s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [01:40<00:05,  1.18s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [01:40<00:03,  1.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [01:41<00:02,  1.17it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [01:41<00:01,  1.32it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [01:42<00:00,  1.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:42<00:00,  1.70it/s]                                               {'loss': 0.0249, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:42<00:00,  1.70it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
                                             [A{'eval_loss': 0.20201610028743744, 'eval_accuracy': 0.933, 'eval_runtime': 2.6562, 'eval_samples_per_second': 376.475, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:45<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A                                               {'train_runtime': 116.861, 'train_samples_per_second': 0.685, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:55<00:00,  1.70it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [17]                  : (0.62, 5.0)
COMET INFO:     eval_accuracy [8]           : (0.803, 0.934)
COMET INFO:     eval_loss [8]               : (0.18942925333976746, 0.6785768866539001)
COMET INFO:     eval_runtime [8]            : (2.6378, 2.6562)
COMET INFO:     eval_samples_per_second [8] : (376.475, 379.11)
COMET INFO:     learning_rate [8]           : (0.0, 4.375e-05)
COMET INFO:     loss [24]                   : (0.006251571234315634, 1.1667)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 116.861
COMET INFO:     train_samples_per_second    : 0.685
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpyog2msfv/aa92912dfbc04d19a8a875aa3036bf9f.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:57<00:00,  1.47s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.03it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.17it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.73it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.46it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.57it/s]{'eval_loss': 0.18942925333976746, 'eval_accuracy': 0.934, 'eval_runtime': 2.7064, 'eval_samples_per_second': 369.488, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.934
COMET INFO:     eval_loss               : 0.18942925333976746
COMET INFO:     eval_runtime            : 2.7064
COMET INFO:     eval_samples_per_second : 369.488
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpe6cgu2mx/16f2623bbfb746f6945c33ec5acb542f.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best were not used when initializing BertForSequenceClassificationWithPooler: ['lm_head.bias', 'lm_head.transform.dense.weight', 'lm_head.transform.dense.bias', 'lm_head.transform.LayerNorm.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'mlp.dense.weight', 'mlp.dense.bias', 'entity_transformation.dense.weight', 'entity_transformation.dense.bias', 'entity_transformation.dense2.weight', 'entity_transformation.dense2.bias', 'hn_entity_transformation.dense.weight', 'hn_entity_transformation.dense.bias', 'hn_entity_transformation.dense2.weight', 'hn_entity_transformation.dense2.bias', 'entity_embedding.weight']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/40 [00:00<?, ?it/s]  2%|â–Ž         | 1/40 [00:01<00:59,  1.53s/it]  5%|â–Œ         | 2/40 [00:02<00:52,  1.39s/it]  8%|â–Š         | 3/40 [00:03<00:47,  1.29s/it] 10%|â–ˆ         | 4/40 [00:04<00:44,  1.23s/it] 12%|â–ˆâ–Ž        | 5/40 [00:05<00:41,  1.18s/it] 15%|â–ˆâ–Œ        | 6/40 [00:06<00:38,  1.14s/it] 18%|â–ˆâ–Š        | 7/40 [00:07<00:36,  1.12s/it] 20%|â–ˆâ–ˆ        | 8/40 [00:08<00:33,  1.05s/it] 22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:09<00:32,  1.05s/it] 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.05s/it]                                               {'loss': 1.1191, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.05s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.11it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.64it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               {'eval_loss': 0.6168079972267151, 'eval_accuracy': 0.806, 'eval_runtime': 2.6462, 'eval_samples_per_second': 377.893, 'epoch': 1.25}

                                             [A 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:13<00:31,  1.05s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 28%|â–ˆâ–ˆâ–Š       | 11/40 [00:20<01:47,  3.72s/it] 30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:21<01:21,  2.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:22<01:03,  2.36s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:23<00:51,  1.96s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:25<00:42,  1.69s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:34,  1.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:30,  1.33s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:28<00:27,  1.24s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:24,  1.18s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:22,  1.14s/it]                                               {'loss': 0.4588, 'learning_rate': 2.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:22,  1.14s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.3232251703739166, 'eval_accuracy': 0.878, 'eval_runtime': 2.6518, 'eval_samples_per_second': 377.108, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:32<00:22,  1.14s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:39<01:10,  3.70s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:40<00:52,  2.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:41<00:40,  2.35s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:42<00:30,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:43<00:24,  1.66s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:44<00:20,  1.48s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:45<00:17,  1.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:47<00:15,  1.27s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:48<00:13,  1.21s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:49<00:11,  1.17s/it]                                               {'loss': 0.2551, 'learning_rate': 1.25e-05, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:49<00:11,  1.17s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
                                             {'eval_loss': 0.2676655054092407, 'eval_accuracy': 0.909, 'eval_runtime': 2.6579, 'eval_samples_per_second': 376.232, 'epoch': 3.75}[A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:51<00:11,  1.17s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:58<00:33,  3.73s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:59<00:22,  2.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [01:00<00:16,  2.33s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [01:01<00:11,  1.94s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [01:02<00:08,  1.68s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [01:03<00:05,  1.49s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [01:05<00:04,  1.36s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [01:06<00:02,  1.27s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [01:07<00:01,  1.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:07<00:00,  1.10s/it]                                               {'loss': 0.184, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:07<00:00,  1.10s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                               {'eval_loss': 0.235566183924675, 'eval_accuracy': 0.916, 'eval_runtime': 2.6616, 'eval_samples_per_second': 375.714, 'epoch': 5.0}
                                             [A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:10<00:00,  1.10s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A                                               {'train_runtime': 81.827, 'train_samples_per_second': 0.489, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:20<00:00,  1.10s/it]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [9]                   : (1.25, 5.0)
COMET INFO:     eval_accuracy [4]           : (0.806, 0.916)
COMET INFO:     eval_loss [4]               : (0.235566183924675, 0.6168079972267151)
COMET INFO:     eval_runtime [4]            : (2.6462, 2.6616)
COMET INFO:     eval_samples_per_second [4] : (375.714, 377.893)
COMET INFO:     learning_rate [4]           : (0.0, 3.7500000000000003e-05)
COMET INFO:     loss [20]                   : (0.024381274357438087, 1.1191)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 81.827
COMET INFO:     train_samples_per_second    : 0.489
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : ../results/my-unsup-mease-data-typehn-18-langs-avg-bert-base-multilingual-cased-best
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForEACL']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmphq9h6x_f/92843ef7f46047eda0d992736b859e81.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:21<00:00,  2.03s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  4.96it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.13it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.70it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.44it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.28it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.11it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.52it/s]{'eval_loss': 0.235566183924675, 'eval_accuracy': 0.916, 'eval_runtime': 2.7177, 'eval_samples_per_second': 367.952, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.916
COMET INFO:     eval_loss               : 0.235566183924675
COMET INFO:     eval_runtime            : 2.7177
COMET INFO:     eval_samples_per_second : 367.952
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpilvhb3n7/8cdd570f0e8c43e8ac18201c7a3ec344.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/160 [00:00<?, ?it/s]  1%|          | 1/160 [00:00<02:06,  1.26it/s]  1%|â–         | 2/160 [00:01<01:41,  1.56it/s]  2%|â–         | 3/160 [00:01<01:23,  1.88it/s]  2%|â–Ž         | 4/160 [00:01<01:11,  2.18it/s]  3%|â–Ž         | 5/160 [00:01<01:02,  2.47it/s]  4%|â–         | 6/160 [00:02<00:56,  2.71it/s]  4%|â–         | 7/160 [00:02<00:52,  2.92it/s]  5%|â–Œ         | 8/160 [00:02<00:49,  3.09it/s]  6%|â–Œ         | 9/160 [00:03<00:47,  3.21it/s]  6%|â–‹         | 10/160 [00:03<00:45,  3.31it/s]                                                {'loss': 1.3546, 'learning_rate': 9.375000000000001e-06, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:03<00:45,  3.31it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.13it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.66it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                
                                             [A{'eval_loss': 1.2857714891433716, 'eval_accuracy': 0.413, 'eval_runtime': 2.6348, 'eval_samples_per_second': 379.529, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:06<00:45,  3.31it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A  7%|â–‹         | 11/160 [00:12<07:25,  2.99s/it]  8%|â–Š         | 12/160 [00:12<05:22,  2.18s/it]  8%|â–Š         | 13/160 [00:13<03:56,  1.61s/it]  9%|â–‰         | 14/160 [00:13<02:56,  1.21s/it]  9%|â–‰         | 15/160 [00:13<02:15,  1.07it/s] 10%|â–ˆ         | 16/160 [00:14<01:46,  1.36it/s] 11%|â–ˆ         | 17/160 [00:14<01:25,  1.66it/s] 11%|â–ˆâ–        | 18/160 [00:14<01:11,  1.98it/s] 12%|â–ˆâ–        | 19/160 [00:14<01:01,  2.28it/s] 12%|â–ˆâ–Ž        | 20/160 [00:15<00:54,  2.55it/s]                                                {'loss': 1.2545, 'learning_rate': 8.750000000000001e-06, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:15<00:54,  2.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.06it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                {'eval_loss': 1.1520686149597168, 'eval_accuracy': 0.62, 'eval_runtime': 2.6324, 'eval_samples_per_second': 379.879, 'epoch': 0.62}

                                             [A 12%|â–ˆâ–Ž        | 20/160 [00:17<00:54,  2.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 13%|â–ˆâ–Ž        | 21/160 [00:24<06:53,  2.97s/it] 14%|â–ˆâ–        | 22/160 [00:24<04:58,  2.16s/it] 14%|â–ˆâ–        | 23/160 [00:24<03:38,  1.60s/it] 15%|â–ˆâ–Œ        | 24/160 [00:24<02:43,  1.20s/it] 16%|â–ˆâ–Œ        | 25/160 [00:25<02:04,  1.08it/s] 16%|â–ˆâ–‹        | 26/160 [00:25<01:37,  1.37it/s] 17%|â–ˆâ–‹        | 27/160 [00:25<01:18,  1.69it/s] 18%|â–ˆâ–Š        | 28/160 [00:26<01:05,  2.01it/s] 18%|â–ˆâ–Š        | 29/160 [00:26<00:56,  2.32it/s] 19%|â–ˆâ–‰        | 30/160 [00:26<00:50,  2.60it/s]                                                {'loss': 1.0791, 'learning_rate': 8.125000000000001e-06, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:26<00:50,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.9164422750473022, 'eval_accuracy': 0.72, 'eval_runtime': 2.6354, 'eval_samples_per_second': 379.449, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:29<00:50,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 19%|â–ˆâ–‰        | 31/160 [00:35<06:17,  2.92s/it] 21%|â–ˆâ–ˆ        | 33/160 [00:35<04:26,  2.10s/it] 21%|â–ˆâ–ˆâ–       | 34/160 [00:36<03:15,  1.55s/it] 22%|â–ˆâ–ˆâ–       | 35/160 [00:36<02:26,  1.17s/it] 22%|â–ˆâ–ˆâ–Ž       | 36/160 [00:36<01:51,  1.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 37/160 [00:36<01:27,  1.40it/s] 24%|â–ˆâ–ˆâ–       | 38/160 [00:37<01:11,  1.72it/s] 24%|â–ˆâ–ˆâ–       | 39/160 [00:37<00:59,  2.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:37<00:51,  2.35it/s]                                                {'loss': 0.8078, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:37<00:51,  2.35it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.6389361619949341, 'eval_accuracy': 0.811, 'eval_runtime': 2.6366, 'eval_samples_per_second': 379.282, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:40<00:51,  2.35it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–Œ       | 41/160 [00:46<05:51,  2.95s/it] 26%|â–ˆâ–ˆâ–‹       | 42/160 [00:46<04:13,  2.15s/it] 27%|â–ˆâ–ˆâ–‹       | 43/160 [00:47<03:05,  1.59s/it] 28%|â–ˆâ–ˆâ–Š       | 44/160 [00:47<02:18,  1.19s/it] 28%|â–ˆâ–ˆâ–Š       | 45/160 [00:47<01:45,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 46/160 [00:47<01:22,  1.38it/s] 29%|â–ˆâ–ˆâ–‰       | 47/160 [00:48<01:06,  1.69it/s] 30%|â–ˆâ–ˆâ–ˆ       | 48/160 [00:48<00:55,  2.01it/s] 31%|â–ˆâ–ˆâ–ˆ       | 49/160 [00:48<00:47,  2.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:49<00:42,  2.60it/s]                                                {'loss': 0.5471, 'learning_rate': 6.875e-06, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:49<00:42,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             {'eval_loss': 0.4794204831123352, 'eval_accuracy': 0.853, 'eval_runtime': 2.6461, 'eval_samples_per_second': 377.919, 'epoch': 1.56}[A
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:51<00:42,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 32%|â–ˆâ–ˆâ–ˆâ–      | 51/160 [00:57<05:18,  2.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/160 [00:58<03:49,  2.13s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/160 [00:58<02:48,  1.57s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 54/160 [00:58<02:05,  1.18s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 55/160 [00:59<01:35,  1.10it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/160 [00:59<01:15,  1.39it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 57/160 [00:59<01:00,  1.69it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 58/160 [00:59<00:50,  2.01it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 59/160 [01:00<00:43,  2.31it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:00<00:38,  2.60it/s]                                                {'loss': 0.443, 'learning_rate': 6.25e-06, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:00<00:38,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.3426344394683838, 'eval_accuracy': 0.886, 'eval_runtime': 2.6403, 'eval_samples_per_second': 378.751, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:03<00:38,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 61/160 [01:09<04:58,  3.02s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 62/160 [01:09<03:35,  2.20s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 63/160 [01:10<02:37,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 65/160 [01:10<01:53,  1.19s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/160 [01:10<01:26,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/160 [01:11<01:07,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/160 [01:11<00:54,  1.68it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 69/160 [01:11<00:45,  1.99it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:11<00:39,  2.29it/s]                                                {'loss': 0.3558, 'learning_rate': 5.625e-06, 'epoch': 2.19}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:11<00:39,  2.29it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.3179077208042145, 'eval_accuracy': 0.886, 'eval_runtime': 2.6411, 'eval_samples_per_second': 378.624, 'epoch': 2.19}

                                             [A 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:14<00:39,  2.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 71/160 [01:21<04:41,  3.17s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/160 [01:21<03:22,  2.30s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 73/160 [01:22<02:27,  1.70s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/160 [01:22<01:49,  1.27s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 75/160 [01:22<01:22,  1.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/160 [01:22<01:04,  1.30it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 77/160 [01:23<00:51,  1.61it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 78/160 [01:23<00:42,  1.92it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 79/160 [01:23<00:36,  2.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:24<00:31,  2.50it/s]                                                {'loss': 0.2482, 'learning_rate': 5e-06, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:24<00:31,  2.50it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.27877143025398254, 'eval_accuracy': 0.894, 'eval_runtime': 2.6455, 'eval_samples_per_second': 378.002, 'epoch': 2.5}

                                             [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:26<00:31,  2.50it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 81/160 [01:33<03:57,  3.01s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/160 [01:33<02:51,  2.19s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 83/160 [01:33<02:04,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 84/160 [01:33<01:32,  1.22s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 85/160 [01:34<01:10,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 86/160 [01:34<00:54,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 87/160 [01:34<00:44,  1.66it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 88/160 [01:35<00:36,  1.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 89/160 [01:35<00:31,  2.27it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:35<00:27,  2.54it/s]                                                {'loss': 0.2694, 'learning_rate': 4.3750000000000005e-06, 'epoch': 2.81}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:35<00:27,  2.54it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.11it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.64it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.2593066096305847, 'eval_accuracy': 0.906, 'eval_runtime': 2.6499, 'eval_samples_per_second': 377.37, 'epoch': 2.81}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:38<00:27,  2.54it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 91/160 [01:44<03:29,  3.04s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 92/160 [01:45<02:30,  2.21s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 93/160 [01:45<01:49,  1.63s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 94/160 [01:45<01:21,  1.23s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 95/160 [01:46<01:01,  1.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 97/160 [01:46<00:45,  1.39it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 98/160 [01:46<00:36,  1.70it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 99/160 [01:46<00:30,  2.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:47<00:25,  2.31it/s]                                                 {'loss': 0.1941, 'learning_rate': 3.7500000000000005e-06, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:47<00:25,  2.31it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 {'eval_loss': 0.25472763180732727, 'eval_accuracy': 0.905, 'eval_runtime': 2.6508, 'eval_samples_per_second': 377.24, 'epoch': 3.12}

                                             [A 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:49<00:25,  2.31it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 101/160 [01:56<02:58,  3.02s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/160 [01:56<02:07,  2.20s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 103/160 [01:56<01:32,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 104/160 [01:57<01:08,  1.22s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 105/160 [01:57<00:51,  1.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 106/160 [01:57<00:39,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 107/160 [01:57<00:31,  1.66it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 108/160 [01:58<00:26,  1.98it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 109/160 [01:58<00:22,  2.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:58<00:19,  2.57it/s]                                                 {'loss': 0.1531, 'learning_rate': 3.125e-06, 'epoch': 3.44}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:58<00:19,  2.57it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 {'eval_loss': 0.2404976487159729, 'eval_accuracy': 0.914, 'eval_runtime': 2.6513, 'eval_samples_per_second': 377.174, 'epoch': 3.44}

                                             [A 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [02:01<00:19,  2.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 111/160 [02:09<02:47,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 112/160 [02:09<01:59,  2.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 113/160 [02:09<01:25,  1.82s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 114/160 [02:10<01:02,  1.36s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 115/160 [02:10<00:46,  1.03s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 116/160 [02:10<00:35,  1.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 117/160 [02:10<00:27,  1.54it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/160 [02:11<00:22,  1.87it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 119/160 [02:11<00:18,  2.18it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:11<00:16,  2.48it/s]                                                 {'loss': 0.1723, 'learning_rate': 2.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:11<00:16,  2.48it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.08it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             [A{'eval_loss': 0.23167181015014648, 'eval_accuracy': 0.911, 'eval_runtime': 2.6541, 'eval_samples_per_second': 376.779, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:14<00:16,  2.48it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 121/160 [02:21<02:05,  3.22s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 122/160 [02:21<01:28,  2.34s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 123/160 [02:22<01:03,  1.72s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 124/160 [02:22<00:46,  1.29s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 125/160 [02:22<00:34,  1.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 126/160 [02:23<00:26,  1.29it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 127/160 [02:23<00:20,  1.60it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 129/160 [02:23<00:15,  2.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:23<00:12,  2.32it/s]                                                 {'loss': 0.1695, 'learning_rate': 1.8750000000000003e-06, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:24<00:12,  2.32it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 {'eval_loss': 0.259829580783844, 'eval_accuracy': 0.906, 'eval_runtime': 2.6477, 'eval_samples_per_second': 377.683, 'epoch': 4.06}
                                             [A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:26<00:12,  2.32it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/160 [02:34<01:38,  3.41s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 132/160 [02:34<01:09,  2.47s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 133/160 [02:34<00:48,  1.81s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/160 [02:35<00:35,  1.35s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 135/160 [02:35<00:25,  1.03s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 136/160 [02:35<00:19,  1.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 137/160 [02:36<00:14,  1.54it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 138/160 [02:36<00:11,  1.85it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 139/160 [02:36<00:09,  2.17it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:36<00:08,  2.45it/s]                                                 {'loss': 0.1105, 'learning_rate': 1.25e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:36<00:08,  2.45it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                 
                                             {'eval_loss': 0.24318771064281464, 'eval_accuracy': 0.905, 'eval_runtime': 2.6442, 'eval_samples_per_second': 378.18, 'epoch': 4.38}[A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:39<00:08,  2.45it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 141/160 [02:45<00:55,  2.91s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 142/160 [02:45<00:38,  2.12s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 143/160 [02:46<00:26,  1.57s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 144/160 [02:46<00:18,  1.18s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 145/160 [02:46<00:13,  1.10it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 146/160 [02:46<00:10,  1.38it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/160 [02:47<00:07,  1.69it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 148/160 [02:47<00:05,  2.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 149/160 [02:47<00:04,  2.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:48<00:03,  2.58it/s]                                                 {'loss': 0.1364, 'learning_rate': 6.25e-07, 'epoch': 4.69}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:48<00:03,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.22600123286247253, 'eval_accuracy': 0.918, 'eval_runtime': 2.6475, 'eval_samples_per_second': 377.708, 'epoch': 4.69}
                                             [A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:50<00:03,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/160 [02:56<00:25,  2.83s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 152/160 [02:56<00:16,  2.07s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/160 [02:57<00:10,  1.53s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/160 [02:57<00:06,  1.16s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 155/160 [02:57<00:04,  1.12it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 156/160 [02:58<00:02,  1.41it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 157/160 [02:58<00:01,  1.72it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 158/160 [02:58<00:00,  2.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 159/160 [02:58<00:00,  2.33it/s]                                                 {'loss': 0.1117, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:59<00:00,  2.33it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.23144948482513428, 'eval_accuracy': 0.917, 'eval_runtime': 2.6459, 'eval_samples_per_second': 377.944, 'epoch': 5.0}
                                             [A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:01<00:00,  2.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A                                                 {'train_runtime': 193.6892, 'train_samples_per_second': 0.826, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:12<00:00,  2.33it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [33]                   : (0.31, 5.0)
COMET INFO:     eval_accuracy [16]           : (0.413, 0.918)
COMET INFO:     eval_loss [16]               : (0.22600123286247253, 1.2857714891433716)
COMET INFO:     eval_runtime [16]            : (2.6324, 2.6541)
COMET INFO:     eval_samples_per_second [16] : (376.779, 379.879)
COMET INFO:     learning_rate [16]           : (0.0, 9.375000000000001e-06)
COMET INFO:     loss [32]                    : (0.05302391201257706, 1.3899575471878052)
COMET INFO:     total_flos                   : 2731876085760000
COMET INFO:     train_runtime                : 193.6892
COMET INFO:     train_samples_per_second     : 0.826
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpxfv2chiu/3b2cbcd8516444349774853507bb6a79.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:14<00:00,  1.22s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.20it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.74it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.48it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s]{'eval_loss': 0.22600123286247253, 'eval_accuracy': 0.918, 'eval_runtime': 2.7247, 'eval_samples_per_second': 367.017, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.918
COMET INFO:     eval_loss               : 0.22600123286247253
COMET INFO:     eval_runtime            : 2.7247
COMET INFO:     eval_samples_per_second : 367.017
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp4i5oh2bb/731b1a3ed9874a4ab37be99aafe4c845.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<01:24,  1.07s/it]  2%|â–Ž         | 2/80 [00:01<01:10,  1.10it/s]  4%|â–         | 3/80 [00:02<01:01,  1.26it/s]  5%|â–Œ         | 4/80 [00:02<00:54,  1.40it/s]  6%|â–‹         | 5/80 [00:03<00:49,  1.51it/s]  8%|â–Š         | 6/80 [00:03<00:46,  1.60it/s]  9%|â–‰         | 7/80 [00:04<00:43,  1.67it/s] 10%|â–ˆ         | 8/80 [00:04<00:41,  1.73it/s] 11%|â–ˆâ–        | 9/80 [00:05<00:40,  1.77it/s] 12%|â–ˆâ–Ž        | 10/80 [00:05<00:38,  1.80it/s]                                               {'loss': 1.34, 'learning_rate': 8.750000000000001e-06, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:05<00:38,  1.80it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.14it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.66it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                               {'eval_loss': 1.2239906787872314, 'eval_accuracy': 0.518, 'eval_runtime': 2.6338, 'eval_samples_per_second': 379.683, 'epoch': 0.62}
                                             [A
 12%|â–ˆâ–Ž        | 10/80 [00:08<00:38,  1.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 14%|â–ˆâ–        | 11/80 [00:15<03:47,  3.29s/it] 15%|â–ˆâ–Œ        | 12/80 [00:16<02:47,  2.46s/it] 16%|â–ˆâ–‹        | 13/80 [00:16<02:06,  1.88s/it] 18%|â–ˆâ–Š        | 14/80 [00:17<01:37,  1.48s/it] 19%|â–ˆâ–‰        | 15/80 [00:17<01:17,  1.20s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:18<01:00,  1.06it/s] 21%|â–ˆâ–ˆâ–       | 17/80 [00:18<00:51,  1.22it/s] 22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:19<00:45,  1.36it/s] 24%|â–ˆâ–ˆâ–       | 19/80 [00:19<00:41,  1.49it/s] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:20<00:37,  1.58it/s]                                               {'loss': 1.1738, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:20<00:37,  1.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             {'eval_loss': 1.0441032648086548, 'eval_accuracy': 0.607, 'eval_runtime': 2.6375, 'eval_samples_per_second': 379.153, 'epoch': 1.25}
[A 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:22<00:37,  1.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:29<03:17,  3.35s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:30<02:25,  2.50s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:30<01:49,  1.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:31<01:23,  1.50s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:31<01:06,  1.21s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/80 [00:32<00:54,  1.01s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:33<00:45,  1.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:33<00:39,  1.31it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:34<00:35,  1.44it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:34<00:32,  1.55it/s]                                               {'loss': 0.9538, 'learning_rate': 6.25e-06, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:34<00:32,  1.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               {'eval_loss': 0.7729045152664185, 'eval_accuracy': 0.8, 'eval_runtime': 2.6434, 'eval_samples_per_second': 378.301, 'epoch': 1.88}
                                             [A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:37<00:32,  1.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:44<02:48,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:44<02:00,  2.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:45<01:30,  1.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/80 [00:46<01:09,  1.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:46<00:54,  1.22s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:47<00:44,  1.01s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:47<00:37,  1.15it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [00:48<00:32,  1.29it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [00:48<00:28,  1.42it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:49<00:26,  1.52it/s]                                               {'loss': 0.709, 'learning_rate': 5e-06, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:49<00:26,  1.52it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.5600135326385498, 'eval_accuracy': 0.849, 'eval_runtime': 2.6482, 'eval_samples_per_second': 377.616, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:51<00:26,  1.52it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [00:58<02:07,  3.26s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/80 [00:59<01:32,  2.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [00:59<01:09,  1.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [01:00<00:52,  1.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:00<00:41,  1.19s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:01<00:33,  1.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:01<00:28,  1.16it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:02<00:22,  1.42it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:02<00:20,  1.53it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:03<00:18,  1.62it/s]                                               {'loss': 0.5119, 'learning_rate': 3.7500000000000005e-06, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:03<00:18,  1.62it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.41801148653030396, 'eval_accuracy': 0.885, 'eval_runtime': 2.6497, 'eval_samples_per_second': 377.394, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:05<00:18,  1.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:12<01:32,  3.20s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:13<01:07,  2.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:13<00:49,  1.85s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:14<00:37,  1.46s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:14<00:29,  1.18s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:15<00:23,  1.01it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:15<00:19,  1.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/80 [01:16<00:16,  1.31it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:16<00:14,  1.44it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:17<00:13,  1.54it/s]                                               {'loss': 0.4007, 'learning_rate': 2.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:17<00:13,  1.54it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.3844127953052521, 'eval_accuracy': 0.875, 'eval_runtime': 2.6508, 'eval_samples_per_second': 377.238, 'epoch': 3.75} 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:20<00:13,  1.54it/s]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:26<01:03,  3.34s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:27<00:44,  2.49s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:28<00:32,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:28<00:23,  1.44s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:28<00:17,  1.17s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [01:29<00:13,  1.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:30<00:11,  1.18it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:30<00:09,  1.33it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:31<00:07,  1.45it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:31<00:06,  1.56it/s]                                               {'loss': 0.3306, 'learning_rate': 1.25e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:31<00:06,  1.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.34777817130088806, 'eval_accuracy': 0.887, 'eval_runtime': 2.6544, 'eval_samples_per_second': 376.74, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:34<00:06,  1.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:40<00:28,  3.13s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:41<00:18,  2.36s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:41<00:12,  1.81s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/80 [01:42<00:08,  1.43s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [01:42<00:05,  1.17s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [01:43<00:03,  1.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [01:43<00:02,  1.18it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [01:44<00:01,  1.32it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [01:44<00:00,  1.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:45<00:00,  1.69it/s]                                               {'loss': 0.309, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:45<00:00,  1.69it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               {'eval_loss': 0.33922553062438965, 'eval_accuracy': 0.888, 'eval_runtime': 2.6576, 'eval_samples_per_second': 376.277, 'epoch': 5.0}

                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:47<00:00,  1.69it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A                                               {'train_runtime': 119.0098, 'train_samples_per_second': 0.672, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:57<00:00,  1.69it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [17]                  : (0.62, 5.0)
COMET INFO:     eval_accuracy [8]           : (0.518, 0.888)
COMET INFO:     eval_loss [8]               : (0.33922553062438965, 1.2239906787872314)
COMET INFO:     eval_runtime [8]            : (2.6338, 2.6576)
COMET INFO:     eval_samples_per_second [8] : (376.277, 379.683)
COMET INFO:     learning_rate [8]           : (0.0, 8.750000000000001e-06)
COMET INFO:     loss [24]                   : (0.13471899926662445, 1.34)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 119.0098
COMET INFO:     train_samples_per_second    : 0.672
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpj2qb25d5/6345076e420440ed9e28ef9738ae7798.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:58<00:00,  1.48s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.48it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.38it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.84it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.53it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s]{'eval_loss': 0.33922553062438965, 'eval_accuracy': 0.888, 'eval_runtime': 2.7045, 'eval_samples_per_second': 369.756, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.888
COMET INFO:     eval_loss               : 0.33922553062438965
COMET INFO:     eval_runtime            : 2.7045
COMET INFO:     eval_samples_per_second : 369.756
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpw3pr3int/b5232159fb304a6d8ff724e8683dd010.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/40 [00:00<?, ?it/s]  2%|â–Ž         | 1/40 [00:01<01:00,  1.56s/it]  5%|â–Œ         | 2/40 [00:02<00:53,  1.41s/it]  8%|â–Š         | 3/40 [00:03<00:48,  1.30s/it] 10%|â–ˆ         | 4/40 [00:04<00:44,  1.23s/it] 12%|â–ˆâ–Ž        | 5/40 [00:05<00:40,  1.17s/it] 15%|â–ˆâ–Œ        | 6/40 [00:06<00:38,  1.13s/it] 18%|â–ˆâ–Š        | 7/40 [00:07<00:36,  1.11s/it] 20%|â–ˆâ–ˆ        | 8/40 [00:08<00:33,  1.03s/it] 22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:09<00:32,  1.04s/it] 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.04s/it]                                               {'loss': 1.3168, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.04s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.11it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.64it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             [A{'eval_loss': 1.188661813735962, 'eval_accuracy': 0.59, 'eval_runtime': 2.6426, 'eval_samples_per_second': 378.42, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:13<00:31,  1.04s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 28%|â–ˆâ–ˆâ–Š       | 11/40 [00:20<01:45,  3.64s/it] 30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:21<01:20,  2.86s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:22<01:02,  2.32s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:23<00:50,  1.94s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:24<00:41,  1.67s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:34,  1.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:30,  1.32s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:27,  1.24s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:28<00:24,  1.18s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:22,  1.14s/it]                                               {'loss': 1.1243, 'learning_rate': 5e-06, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:22,  1.14s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.9918652176856995, 'eval_accuracy': 0.679, 'eval_runtime': 2.6488, 'eval_samples_per_second': 377.529, 'epoch': 2.5} 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:32<00:22,  1.14s/it]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:39<01:10,  3.71s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:40<00:52,  2.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:41<00:40,  2.36s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:42<00:30,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:43<00:24,  1.66s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:44<00:20,  1.48s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:45<00:17,  1.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:46<00:15,  1.27s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:47<00:13,  1.21s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:48<00:11,  1.17s/it]                                               {'loss': 0.8913, 'learning_rate': 2.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:48<00:11,  1.17s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
                                             [A{'eval_loss': 0.7515891194343567, 'eval_accuracy': 0.809, 'eval_runtime': 2.6543, 'eval_samples_per_second': 376.748, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:51<00:11,  1.17s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:58<00:33,  3.70s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:59<00:22,  2.85s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [01:00<00:16,  2.32s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [01:01<00:11,  1.94s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [01:02<00:08,  1.68s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [01:03<00:05,  1.50s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [01:04<00:04,  1.37s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [01:05<00:02,  1.28s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [01:06<00:01,  1.22s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:07<00:00,  1.11s/it]                                               {'loss': 0.7592, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:07<00:00,  1.11s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               {'eval_loss': 0.6717634201049805, 'eval_accuracy': 0.838, 'eval_runtime': 2.6671, 'eval_samples_per_second': 374.933, 'epoch': 5.0}
                                             [A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:10<00:00,  1.11s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A                                               {'train_runtime': 81.1701, 'train_samples_per_second': 0.493, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:20<00:00,  1.11s/it]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [9]                   : (1.25, 5.0)
COMET INFO:     eval_accuracy [4]           : (0.59, 0.838)
COMET INFO:     eval_loss [4]               : (0.6717634201049805, 1.188661813735962)
COMET INFO:     eval_runtime [4]            : (2.6426, 2.6671)
COMET INFO:     eval_samples_per_second [4] : (374.933, 378.42)
COMET INFO:     learning_rate [4]           : (0.0, 7.500000000000001e-06)
COMET INFO:     loss [20]                   : (0.17523962259292603, 1.3168)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 81.1701
COMET INFO:     train_samples_per_second    : 0.493
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpj_wgqyop/7901c21c945e4e78a74c16e369002197.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:20<00:00,  2.01s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.28it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.29it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.78it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.49it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.69it/s]{'eval_loss': 0.6717634201049805, 'eval_accuracy': 0.838, 'eval_runtime': 2.7247, 'eval_samples_per_second': 367.013, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.838
COMET INFO:     eval_loss               : 0.6717634201049805
COMET INFO:     eval_runtime            : 2.7247
COMET INFO:     eval_samples_per_second : 367.013
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp44rby61n/29a2ecf0c355442aad3da7f9c48568a6.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/160 [00:00<?, ?it/s]  1%|          | 1/160 [00:00<02:01,  1.31it/s]  1%|â–         | 2/160 [00:01<01:37,  1.62it/s]  2%|â–         | 3/160 [00:01<01:20,  1.94it/s]  2%|â–Ž         | 4/160 [00:01<01:09,  2.26it/s]  3%|â–Ž         | 5/160 [00:01<01:00,  2.54it/s]  4%|â–         | 6/160 [00:02<00:55,  2.80it/s]  4%|â–         | 7/160 [00:02<00:50,  3.00it/s]  5%|â–Œ         | 8/160 [00:02<00:48,  3.16it/s]  6%|â–Œ         | 9/160 [00:02<00:45,  3.29it/s]  6%|â–‹         | 10/160 [00:03<00:44,  3.39it/s]                                                {'loss': 1.2904, 'learning_rate': 2.8125e-05, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:03<00:44,  3.39it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.14it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                {'eval_loss': 1.0445808172225952, 'eval_accuracy': 0.579, 'eval_runtime': 2.6345, 'eval_samples_per_second': 379.574, 'epoch': 0.31}

                                             [A  6%|â–‹         | 10/160 [00:05<00:44,  3.39it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A  7%|â–‹         | 11/160 [00:12<07:04,  2.85s/it]  8%|â–Š         | 12/160 [00:12<05:07,  2.08s/it]  8%|â–Š         | 13/160 [00:12<03:46,  1.54s/it]  9%|â–‰         | 14/160 [00:12<02:49,  1.16s/it]  9%|â–‰         | 15/160 [00:13<02:10,  1.12it/s] 10%|â–ˆ         | 16/160 [00:13<01:42,  1.40it/s] 11%|â–ˆ         | 17/160 [00:13<01:23,  1.71it/s] 11%|â–ˆâ–        | 18/160 [00:14<01:09,  2.03it/s] 12%|â–ˆâ–        | 19/160 [00:14<01:00,  2.33it/s] 12%|â–ˆâ–Ž        | 20/160 [00:14<00:53,  2.60it/s]                                                {'loss': 0.8392, 'learning_rate': 2.625e-05, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:14<00:53,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                
                                             [A{'eval_loss': 0.5163387656211853, 'eval_accuracy': 0.811, 'eval_runtime': 2.6365, 'eval_samples_per_second': 379.291, 'epoch': 0.62} 12%|â–ˆâ–Ž        | 20/160 [00:17<00:53,  2.60it/s]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 13%|â–ˆâ–Ž        | 21/160 [00:23<06:46,  2.92s/it] 14%|â–ˆâ–        | 22/160 [00:23<04:53,  2.13s/it] 14%|â–ˆâ–        | 23/160 [00:23<03:35,  1.57s/it] 15%|â–ˆâ–Œ        | 24/160 [00:24<02:40,  1.18s/it] 16%|â–ˆâ–Œ        | 25/160 [00:24<02:02,  1.10it/s] 16%|â–ˆâ–‹        | 26/160 [00:24<01:36,  1.39it/s] 17%|â–ˆâ–‹        | 27/160 [00:25<01:17,  1.71it/s] 18%|â–ˆâ–Š        | 28/160 [00:25<01:05,  2.03it/s] 18%|â–ˆâ–Š        | 29/160 [00:25<00:56,  2.34it/s] 19%|â–ˆâ–‰        | 30/160 [00:25<00:49,  2.61it/s]                                                {'loss': 0.4271, 'learning_rate': 2.4375e-05, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:25<00:49,  2.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.2778792083263397, 'eval_accuracy': 0.902, 'eval_runtime': 2.6379, 'eval_samples_per_second': 379.093, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:28<00:49,  2.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 19%|â–ˆâ–‰        | 31/160 [00:34<06:18,  2.94s/it] 21%|â–ˆâ–ˆ        | 33/160 [00:35<04:28,  2.11s/it] 21%|â–ˆâ–ˆâ–       | 34/160 [00:35<03:16,  1.56s/it] 22%|â–ˆâ–ˆâ–       | 35/160 [00:35<02:27,  1.18s/it] 22%|â–ˆâ–ˆâ–Ž       | 36/160 [00:36<01:52,  1.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 37/160 [00:36<01:28,  1.39it/s] 24%|â–ˆâ–ˆâ–       | 38/160 [00:36<01:11,  1.70it/s] 24%|â–ˆâ–ˆâ–       | 39/160 [00:36<01:00,  2.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:37<00:51,  2.32it/s]                                                {'loss': 0.3427, 'learning_rate': 2.25e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:37<00:51,  2.32it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             {'eval_loss': 0.6813529133796692, 'eval_accuracy': 0.76, 'eval_runtime': 2.6405, 'eval_samples_per_second': 378.718, 'epoch': 1.25}[A
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:39<00:51,  2.32it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–Œ       | 41/160 [00:45<05:50,  2.95s/it] 26%|â–ˆâ–ˆâ–‹       | 42/160 [00:46<04:13,  2.15s/it] 27%|â–ˆâ–ˆâ–‹       | 43/160 [00:46<03:05,  1.59s/it] 28%|â–ˆâ–ˆâ–Š       | 44/160 [00:46<02:18,  1.19s/it] 28%|â–ˆâ–ˆâ–Š       | 45/160 [00:47<01:45,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 46/160 [00:47<01:22,  1.38it/s] 29%|â–ˆâ–ˆâ–‰       | 47/160 [00:47<01:06,  1.69it/s] 30%|â–ˆâ–ˆâ–ˆ       | 48/160 [00:47<00:55,  2.01it/s] 31%|â–ˆâ–ˆâ–ˆ       | 49/160 [00:48<00:47,  2.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:48<00:42,  2.60it/s]                                                {'loss': 0.2871, 'learning_rate': 2.0625e-05, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:48<00:42,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.2603107690811157, 'eval_accuracy': 0.904, 'eval_runtime': 2.6461, 'eval_samples_per_second': 377.922, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:51<00:42,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 32%|â–ˆâ–ˆâ–ˆâ–      | 51/160 [00:57<05:19,  2.93s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/160 [00:57<03:50,  2.13s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/160 [00:57<02:48,  1.58s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 54/160 [00:58<02:06,  1.19s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 55/160 [00:58<01:36,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/160 [00:58<01:15,  1.38it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 57/160 [00:58<01:01,  1.69it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 58/160 [00:59<00:51,  2.00it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 59/160 [00:59<00:43,  2.30it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [00:59<00:38,  2.57it/s]                                                {'loss': 0.2021, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [00:59<00:38,  2.57it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.2882895767688751, 'eval_accuracy': 0.894, 'eval_runtime': 2.6513, 'eval_samples_per_second': 377.17, 'epoch': 1.88}
                                             [A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:02<00:38,  2.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 61/160 [01:08<04:48,  2.91s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 62/160 [01:08<03:28,  2.12s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 63/160 [01:09<02:32,  1.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 65/160 [01:09<01:49,  1.16s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/160 [01:09<01:23,  1.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/160 [01:10<01:05,  1.41it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/160 [01:10<00:53,  1.73it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 69/160 [01:10<00:44,  2.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:10<00:38,  2.35it/s]                                                {'loss': 0.1208, 'learning_rate': 1.6875e-05, 'epoch': 2.19}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:10<00:38,  2.35it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.14972586929798126, 'eval_accuracy': 0.945, 'eval_runtime': 2.6458, 'eval_samples_per_second': 377.957, 'epoch': 2.19} 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:13<00:38,  2.35it/s]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 71/160 [01:19<04:20,  2.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/160 [01:20<03:07,  2.13s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 73/160 [01:20<02:17,  1.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/160 [01:20<01:41,  1.18s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 75/160 [01:20<01:17,  1.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/160 [01:21<01:00,  1.39it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 77/160 [01:21<00:48,  1.70it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 78/160 [01:21<00:40,  2.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 79/160 [01:21<00:34,  2.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:22<00:30,  2.61it/s]                                                {'loss': 0.0791, 'learning_rate': 1.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:22<00:30,  2.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                
                                             [A{'eval_loss': 0.16016128659248352, 'eval_accuracy': 0.946, 'eval_runtime': 2.6436, 'eval_samples_per_second': 378.276, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:24<00:30,  2.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 81/160 [01:31<03:51,  2.93s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/160 [01:31<02:46,  2.14s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 83/160 [01:31<02:01,  1.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 84/160 [01:31<01:30,  1.19s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 85/160 [01:32<01:08,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 86/160 [01:32<00:53,  1.38it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 87/160 [01:32<00:43,  1.69it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 88/160 [01:33<00:35,  2.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 89/160 [01:33<00:30,  2.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:33<00:27,  2.58it/s]                                                {'loss': 0.1133, 'learning_rate': 1.3125e-05, 'epoch': 2.81}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:33<00:27,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                
{'eval_loss': 0.16949132084846497, 'eval_accuracy': 0.943, 'eval_runtime': 2.6457, 'eval_samples_per_second': 377.976, 'epoch': 2.81}
                                             [A 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:36<00:27,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 91/160 [01:42<03:26,  2.99s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 92/160 [01:42<02:27,  2.17s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 93/160 [01:43<01:47,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 94/160 [01:43<01:19,  1.21s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 95/160 [01:43<01:00,  1.08it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 97/160 [01:44<00:44,  1.42it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 98/160 [01:44<00:35,  1.74it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 99/160 [01:44<00:29,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:44<00:25,  2.37it/s]                                                 {'loss': 0.0504, 'learning_rate': 1.125e-05, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:44<00:25,  2.37it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             [A{'eval_loss': 0.16613973677158356, 'eval_accuracy': 0.944, 'eval_runtime': 2.6518, 'eval_samples_per_second': 377.096, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:47<00:25,  2.37it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 101/160 [01:53<02:57,  3.00s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/160 [01:54<02:06,  2.18s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 103/160 [01:54<01:31,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 104/160 [01:54<01:07,  1.21s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 105/160 [01:55<00:51,  1.08it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 106/160 [01:55<00:39,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 107/160 [01:55<00:31,  1.68it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 108/160 [01:55<00:25,  2.00it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 109/160 [01:56<00:22,  2.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:56<00:19,  2.59it/s]                                                 {'loss': 0.0104, 'learning_rate': 9.375000000000001e-06, 'epoch': 3.44}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:56<00:19,  2.59it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                                 
                                             {'eval_loss': 0.16807420551776886, 'eval_accuracy': 0.95, 'eval_runtime': 2.6555, 'eval_samples_per_second': 376.582, 'epoch': 3.44}[A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:59<00:19,  2.59it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 111/160 [02:05<02:24,  2.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 112/160 [02:05<01:43,  2.15s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 113/160 [02:05<01:14,  1.59s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 114/160 [02:06<00:55,  1.20s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 115/160 [02:06<00:41,  1.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 116/160 [02:06<00:31,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 117/160 [02:07<00:25,  1.68it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/160 [02:07<00:20,  2.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 119/160 [02:07<00:17,  2.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:07<00:15,  2.58it/s]                                                 {'loss': 0.0303, 'learning_rate': 7.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:07<00:15,  2.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.91it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                                 
                                             [A{'eval_loss': 0.16149501502513885, 'eval_accuracy': 0.947, 'eval_runtime': 2.6587, 'eval_samples_per_second': 376.12, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:10<00:15,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 121/160 [02:16<01:53,  2.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 122/160 [02:17<01:20,  2.13s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 123/160 [02:17<00:58,  1.57s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 124/160 [02:17<00:42,  1.18s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 125/160 [02:17<00:31,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 126/160 [02:18<00:24,  1.39it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 127/160 [02:18<00:19,  1.70it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 129/160 [02:18<00:14,  2.15it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:19<00:12,  2.45it/s]                                                 {'loss': 0.0239, 'learning_rate': 5.625e-06, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:19<00:12,  2.45it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                                 
                                             [A{'eval_loss': 0.17970187962055206, 'eval_accuracy': 0.946, 'eval_runtime': 2.66, 'eval_samples_per_second': 375.934, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:21<00:12,  2.45it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/160 [02:27<01:23,  2.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 132/160 [02:27<00:58,  2.09s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 133/160 [02:28<00:41,  1.55s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/160 [02:28<00:30,  1.17s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 135/160 [02:28<00:22,  1.11it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 136/160 [02:29<00:17,  1.40it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 137/160 [02:29<00:13,  1.72it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 138/160 [02:29<00:10,  2.05it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 139/160 [02:29<00:08,  2.35it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:30<00:07,  2.63it/s]                                                 {'loss': 0.0034, 'learning_rate': 3.75e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:30<00:07,  2.63it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.98it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                                 {'eval_loss': 0.16564160585403442, 'eval_accuracy': 0.953, 'eval_runtime': 2.6605, 'eval_samples_per_second': 375.865, 'epoch': 4.38}

                                             [A 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:32<00:07,  2.63it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 141/160 [02:38<00:55,  2.91s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 142/160 [02:39<00:38,  2.12s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 143/160 [02:39<00:26,  1.57s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 144/160 [02:39<00:18,  1.18s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 145/160 [02:40<00:13,  1.10it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 146/160 [02:40<00:10,  1.39it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/160 [02:40<00:07,  1.70it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 148/160 [02:40<00:05,  2.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 149/160 [02:41<00:04,  2.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:41<00:03,  2.61it/s]                                                 {'loss': 0.0094, 'learning_rate': 1.875e-06, 'epoch': 4.69}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:41<00:03,  2.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                                 {'eval_loss': 0.16278614103794098, 'eval_accuracy': 0.953, 'eval_runtime': 2.6634, 'eval_samples_per_second': 375.46, 'epoch': 4.69}
                                             [A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:44<00:03,  2.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/160 [02:50<00:25,  2.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 152/160 [02:50<00:16,  2.11s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/160 [02:50<00:10,  1.56s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/160 [02:51<00:07,  1.17s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 155/160 [02:51<00:04,  1.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 156/160 [02:51<00:02,  1.40it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 157/160 [02:51<00:01,  1.71it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 158/160 [02:52<00:00,  2.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 159/160 [02:52<00:00,  2.34it/s]                                                 {'loss': 0.0028, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:52<00:00,  2.34it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A                                                 
                                             [A{'eval_loss': 0.1640276461839676, 'eval_accuracy': 0.953, 'eval_runtime': 2.6581, 'eval_samples_per_second': 376.214, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:55<00:00,  2.34it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s][A
                                             [A                                                 {'train_runtime': 186.1158, 'train_samples_per_second': 0.86, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:04<00:00,  2.34it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [33]                   : (0.31, 5.0)
COMET INFO:     eval_accuracy [16]           : (0.579, 0.953)
COMET INFO:     eval_loss [16]               : (0.14972586929798126, 1.0445808172225952)
COMET INFO:     eval_runtime [16]            : (2.6345, 2.6634)
COMET INFO:     eval_samples_per_second [16] : (375.46, 379.574)
COMET INFO:     learning_rate [16]           : (0.0, 2.8125e-05)
COMET INFO:     loss [32]                    : (0.0028, 1.3899575471878052)
COMET INFO:     total_flos                   : 2731876085760000
COMET INFO:     train_runtime                : 186.1158
COMET INFO:     train_samples_per_second     : 0.86
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp_6vkv4kb/1f7440a5d7e34007a2cf46914baac4c2.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:05<00:00,  1.16s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.24it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.76it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.47it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.63it/s]{'eval_loss': 0.16564160585403442, 'eval_accuracy': 0.953, 'eval_runtime': 2.7427, 'eval_samples_per_second': 364.599, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.953
COMET INFO:     eval_loss               : 0.16564160585403442
COMET INFO:     eval_runtime            : 2.7427
COMET INFO:     eval_samples_per_second : 364.599
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpfpupqihp/85f77ad824b44024b6fc939b9d011e6a.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<01:40,  1.28s/it]  2%|â–Ž         | 2/80 [00:01<01:22,  1.05s/it]  4%|â–         | 3/80 [00:02<01:09,  1.11it/s]  5%|â–Œ         | 4/80 [00:02<00:59,  1.27it/s]  6%|â–‹         | 5/80 [00:03<00:53,  1.40it/s]  8%|â–Š         | 6/80 [00:03<00:48,  1.52it/s]  9%|â–‰         | 7/80 [00:04<00:45,  1.61it/s] 10%|â–ˆ         | 8/80 [00:05<00:42,  1.68it/s] 11%|â–ˆâ–        | 9/80 [00:05<00:40,  1.73it/s] 12%|â–ˆâ–Ž        | 10/80 [00:06<00:39,  1.77it/s]                                               {'loss': 1.2429, 'learning_rate': 2.625e-05, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:06<00:39,  1.77it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.12it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.97it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             [A{'eval_loss': 0.8510110974311829, 'eval_accuracy': 0.78, 'eval_runtime': 2.6438, 'eval_samples_per_second': 378.25, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:08<00:39,  1.77it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 14%|â–ˆâ–        | 11/80 [00:15<03:38,  3.17s/it] 15%|â–ˆâ–Œ        | 12/80 [00:15<02:41,  2.38s/it] 16%|â–ˆâ–‹        | 13/80 [00:16<02:02,  1.83s/it] 18%|â–ˆâ–Š        | 14/80 [00:16<01:35,  1.44s/it] 19%|â–ˆâ–‰        | 15/80 [00:17<01:16,  1.17s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:17<00:59,  1.08it/s] 21%|â–ˆâ–ˆâ–       | 17/80 [00:18<00:50,  1.24it/s] 22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:18<00:44,  1.38it/s] 24%|â–ˆâ–ˆâ–       | 19/80 [00:19<00:40,  1.50it/s] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:37,  1.60it/s]                                               {'loss': 0.6201, 'learning_rate': 2.25e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:37,  1.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.3957033157348633, 'eval_accuracy': 0.864, 'eval_runtime': 2.6497, 'eval_samples_per_second': 377.397, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:22<00:37,  1.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:29<03:11,  3.24s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:29<02:20,  2.43s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:30<01:46,  1.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:30<01:22,  1.47s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:31<01:05,  1.19s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/80 [00:32<00:53,  1.00it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:32<00:45,  1.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:33<00:39,  1.31it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:33<00:35,  1.43it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:34<00:32,  1.53it/s]                                               {'loss': 0.3395, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:34<00:32,  1.53it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.3255511224269867, 'eval_accuracy': 0.889, 'eval_runtime': 2.6468, 'eval_samples_per_second': 377.819, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:36<00:32,  1.53it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:43<02:39,  3.25s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:43<01:54,  2.38s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:44<01:26,  1.83s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/80 [00:44<01:06,  1.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:45<00:52,  1.17s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:46<00:43,  1.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:46<00:36,  1.17it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [00:47<00:31,  1.32it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [00:47<00:28,  1.44it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:48<00:25,  1.54it/s]                                               {'loss': 0.2223, 'learning_rate': 1.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:48<00:25,  1.54it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.2396842986345291, 'eval_accuracy': 0.907, 'eval_runtime': 2.6559, 'eval_samples_per_second': 376.523, 'epoch': 2.5}
                                             [A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:50<00:25,  1.54it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [00:57<02:04,  3.19s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/80 [00:57<01:31,  2.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [00:58<01:08,  1.84s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [00:58<00:52,  1.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [00:59<00:41,  1.18s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:00<00:33,  1.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:00<00:28,  1.17it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:00<00:22,  1.41it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:01<00:20,  1.52it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:02<00:18,  1.60it/s]                                               {'loss': 0.145, 'learning_rate': 1.125e-05, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:02<00:18,  1.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.17445650696754456, 'eval_accuracy': 0.933, 'eval_runtime': 2.6559, 'eval_samples_per_second': 376.518, 'epoch': 3.12}

                                             [A 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:04<00:18,  1.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:11<01:32,  3.20s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:11<01:07,  2.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:12<00:49,  1.84s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:12<00:37,  1.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:13<00:29,  1.17s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:13<00:23,  1.02it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:14<00:19,  1.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/80 [01:15<00:16,  1.33it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:15<00:14,  1.45it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:16<00:12,  1.56it/s]                                               {'loss': 0.0839, 'learning_rate': 7.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:16<00:12,  1.56it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               {'eval_loss': 0.1656322032213211, 'eval_accuracy': 0.941, 'eval_runtime': 2.6573, 'eval_samples_per_second': 376.316, 'epoch': 3.75}
                                             [A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:18<00:12,  1.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:25<01:00,  3.19s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:25<00:43,  2.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:26<00:31,  1.84s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:26<00:22,  1.39s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:27<00:17,  1.14s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [01:27<00:13,  1.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:28<00:10,  1.20it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:28<00:08,  1.33it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:29<00:07,  1.45it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:29<00:06,  1.55it/s]                                               {'loss': 0.0616, 'learning_rate': 3.75e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:29<00:06,  1.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               {'eval_loss': 0.18784725666046143, 'eval_accuracy': 0.932, 'eval_runtime': 2.6567, 'eval_samples_per_second': 376.404, 'epoch': 4.38}
                                             [A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:32<00:06,  1.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:39<00:28,  3.18s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:39<00:19,  2.39s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:40<00:12,  1.83s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/80 [01:40<00:08,  1.45s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [01:41<00:05,  1.18s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [01:41<00:03,  1.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [01:42<00:02,  1.17it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [01:42<00:01,  1.31it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [01:43<00:00,  1.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:43<00:00,  1.69it/s]                                               {'loss': 0.0449, 'learning_rate': 0.0, 'epoch': 5.0}100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:43<00:00,  1.69it/s]

  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
                                             [A{'eval_loss': 0.17564289271831512, 'eval_accuracy': 0.935, 'eval_runtime': 2.6568, 'eval_samples_per_second': 376.393, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:46<00:00,  1.69it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A                                               {'train_runtime': 117.5693, 'train_samples_per_second': 0.68, 'epoch': 5.0}100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:56<00:00,  1.69it/s]
COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [17]                  : (0.62, 5.0)
COMET INFO:     eval_accuracy [8]           : (0.78, 0.941)
COMET INFO:     eval_loss [8]               : (0.1656322032213211, 0.8510110974311829)
COMET INFO:     eval_runtime [8]            : (2.6438, 2.6573)
COMET INFO:     eval_samples_per_second [8] : (376.316, 378.25)
COMET INFO:     learning_rate [8]           : (0.0, 2.625e-05)
COMET INFO:     loss [24]                   : (0.008640922605991364, 1.2429)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 117.5693
COMET INFO:     train_samples_per_second    : 0.68
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpw8fqszqt/5727ae47e85740dba6ea1a66992c0a49.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:57<00:00,  1.47s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.00it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.16it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.72it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.45it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.65it/s]{'eval_loss': 0.1656322032213211, 'eval_accuracy': 0.941, 'eval_runtime': 2.7114, 'eval_samples_per_second': 368.818, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.941
COMET INFO:     eval_loss               : 0.1656322032213211
COMET INFO:     eval_runtime            : 2.7114
COMET INFO:     eval_samples_per_second : 368.818
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpy2g9qq0r/003623dff3b543aa93c468c40167b6a1.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/40 [00:00<?, ?it/s]  2%|â–Ž         | 1/40 [00:01<01:01,  1.57s/it]  5%|â–Œ         | 2/40 [00:02<00:53,  1.41s/it]  8%|â–Š         | 3/40 [00:03<00:48,  1.30s/it] 10%|â–ˆ         | 4/40 [00:04<00:44,  1.23s/it] 12%|â–ˆâ–Ž        | 5/40 [00:05<00:41,  1.18s/it] 15%|â–ˆâ–Œ        | 6/40 [00:06<00:38,  1.15s/it] 18%|â–ˆâ–Š        | 7/40 [00:07<00:37,  1.12s/it] 20%|â–ˆâ–ˆ        | 8/40 [00:08<00:33,  1.05s/it] 22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:09<00:32,  1.05s/it] 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.05s/it]                                               {'loss': 1.268, 'learning_rate': 2.25e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.05s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.11it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.64it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.97it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             [A{'eval_loss': 0.9153785109519958, 'eval_accuracy': 0.72, 'eval_runtime': 2.6457, 'eval_samples_per_second': 377.978, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:13<00:31,  1.05s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 28%|â–ˆâ–ˆâ–Š       | 11/40 [00:20<01:45,  3.63s/it] 30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:21<01:20,  2.86s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:22<01:02,  2.32s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:23<00:50,  1.93s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:24<00:41,  1.67s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:34,  1.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:30,  1.32s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:27,  1.25s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:28<00:24,  1.19s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:22,  1.15s/it]                                               {'loss': 0.6272, 'learning_rate': 1.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:22,  1.15s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.40469568967819214, 'eval_accuracy': 0.861, 'eval_runtime': 2.6572, 'eval_samples_per_second': 376.34, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:32<00:22,  1.15s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:39<01:11,  3.77s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:40<00:53,  2.96s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:41<00:40,  2.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:42<00:31,  1.94s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:43<00:25,  1.68s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:44<00:20,  1.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:45<00:17,  1.37s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:47<00:15,  1.28s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:48<00:13,  1.22s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:49<00:11,  1.17s/it]                                               {'loss': 0.2803, 'learning_rate': 7.5e-06, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:49<00:11,  1.17s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.36it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
{'eval_loss': 0.2772828936576843, 'eval_accuracy': 0.9, 'eval_runtime': 2.658, 'eval_samples_per_second': 376.217, 'epoch': 3.75}                                             [A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:51<00:11,  1.17s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:58<00:33,  3.72s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:59<00:22,  2.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [01:00<00:16,  2.33s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [01:01<00:11,  1.95s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [01:02<00:08,  1.69s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [01:04<00:06,  1.50s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [01:05<00:04,  1.37s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [01:06<00:02,  1.28s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [01:07<00:01,  1.22s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:08<00:00,  1.12s/it]                                               {'loss': 0.2203, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:08<00:00,  1.12s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.99it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.58it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.92it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.57it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.35it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               {'eval_loss': 0.25453925132751465, 'eval_accuracy': 0.903, 'eval_runtime': 2.66, 'eval_samples_per_second': 375.938, 'epoch': 5.0}

                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:10<00:00,  1.12s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A                                               {'train_runtime': 81.9903, 'train_samples_per_second': 0.488, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:20<00:00,  1.12s/it]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [9]                   : (1.25, 5.0)
COMET INFO:     eval_accuracy [4]           : (0.72, 0.903)
COMET INFO:     eval_loss [4]               : (0.25453925132751465, 0.9153785109519958)
COMET INFO:     eval_runtime [4]            : (2.6457, 2.66)
COMET INFO:     eval_samples_per_second [4] : (375.938, 377.978)
COMET INFO:     learning_rate [4]           : (0.0, 2.25e-05)
COMET INFO:     loss [20]                   : (0.04664316400885582, 1.268)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 81.9903
COMET INFO:     train_samples_per_second    : 0.488
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpfq_18_hd/afe781820b254ae89ceeaf0b4b7363de.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:21<00:00,  2.04s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.46it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.82it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.71it/s]{'eval_loss': 0.25453925132751465, 'eval_accuracy': 0.903, 'eval_runtime': 2.6838, 'eval_samples_per_second': 372.6, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.903
COMET INFO:     eval_loss               : 0.25453925132751465
COMET INFO:     eval_runtime            : 2.6838
COMET INFO:     eval_samples_per_second : 372.6
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpo0weyrno/d43eb0893a4446f29b73049ada05847e.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/160 [00:00<?, ?it/s]  1%|          | 1/160 [00:00<02:01,  1.31it/s]  1%|â–         | 2/160 [00:01<01:37,  1.62it/s]  2%|â–         | 3/160 [00:01<01:21,  1.93it/s]  2%|â–Ž         | 4/160 [00:01<01:09,  2.24it/s]  3%|â–Ž         | 5/160 [00:01<01:01,  2.52it/s]  4%|â–         | 6/160 [00:02<00:55,  2.76it/s]  4%|â–         | 7/160 [00:02<00:51,  2.95it/s]  5%|â–Œ         | 8/160 [00:02<00:48,  3.11it/s]  6%|â–Œ         | 9/160 [00:03<00:46,  3.24it/s]  6%|â–‹         | 10/160 [00:03<00:45,  3.33it/s]                                                {'loss': 1.2047, 'learning_rate': 4.6875e-05, 'epoch': 0.31}
  6%|â–‹         | 10/160 [00:03<00:45,  3.33it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.12it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                                {'eval_loss': 0.7786818742752075, 'eval_accuracy': 0.614, 'eval_runtime': 2.6392, 'eval_samples_per_second': 378.906, 'epoch': 0.31}
                                             [A
  6%|â–‹         | 10/160 [00:05<00:45,  3.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A  7%|â–‹         | 11/160 [00:12<07:10,  2.89s/it]  8%|â–Š         | 12/160 [00:12<05:11,  2.11s/it]  8%|â–Š         | 13/160 [00:12<03:49,  1.56s/it]  9%|â–‰         | 14/160 [00:13<02:51,  1.18s/it]  9%|â–‰         | 15/160 [00:13<02:11,  1.10it/s] 10%|â–ˆ         | 16/160 [00:13<01:43,  1.39it/s] 11%|â–ˆ         | 17/160 [00:13<01:24,  1.70it/s] 11%|â–ˆâ–        | 18/160 [00:14<01:10,  2.01it/s] 12%|â–ˆâ–        | 19/160 [00:14<01:01,  2.31it/s] 12%|â–ˆâ–Ž        | 20/160 [00:14<00:54,  2.59it/s]                                                {'loss': 0.6362, 'learning_rate': 4.375e-05, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:14<00:54,  2.59it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             [A{'eval_loss': 0.34743764996528625, 'eval_accuracy': 0.867, 'eval_runtime': 2.6424, 'eval_samples_per_second': 378.445, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 20/160 [00:17<00:54,  2.59it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 13%|â–ˆâ–Ž        | 21/160 [00:23<06:44,  2.91s/it] 14%|â–ˆâ–        | 22/160 [00:23<04:52,  2.12s/it] 14%|â–ˆâ–        | 23/160 [00:24<03:34,  1.57s/it] 15%|â–ˆâ–Œ        | 24/160 [00:24<02:40,  1.18s/it] 16%|â–ˆâ–Œ        | 25/160 [00:24<02:02,  1.10it/s] 16%|â–ˆâ–‹        | 26/160 [00:24<01:36,  1.39it/s] 17%|â–ˆâ–‹        | 27/160 [00:25<01:17,  1.71it/s] 18%|â–ˆâ–Š        | 28/160 [00:25<01:05,  2.03it/s] 18%|â–ˆâ–Š        | 29/160 [00:25<00:56,  2.33it/s] 19%|â–ˆâ–‰        | 30/160 [00:26<00:49,  2.61it/s]                                                {'loss': 0.3597, 'learning_rate': 4.0625000000000005e-05, 'epoch': 0.94}
 19%|â–ˆâ–‰        | 30/160 [00:26<00:49,  2.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                {'eval_loss': 0.2093207687139511, 'eval_accuracy': 0.927, 'eval_runtime': 2.6411, 'eval_samples_per_second': 378.635, 'epoch': 0.94}

                                             [A 19%|â–ˆâ–‰        | 30/160 [00:28<00:49,  2.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 19%|â–ˆâ–‰        | 31/160 [00:34<06:13,  2.90s/it] 21%|â–ˆâ–ˆ        | 33/160 [00:35<04:24,  2.08s/it] 21%|â–ˆâ–ˆâ–       | 34/160 [00:35<03:14,  1.54s/it] 22%|â–ˆâ–ˆâ–       | 35/160 [00:35<02:25,  1.16s/it] 22%|â–ˆâ–ˆâ–Ž       | 36/160 [00:36<01:51,  1.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 37/160 [00:36<01:27,  1.40it/s] 24%|â–ˆâ–ˆâ–       | 38/160 [00:36<01:11,  1.71it/s] 24%|â–ˆâ–ˆâ–       | 39/160 [00:36<00:59,  2.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:37<00:51,  2.33it/s]                                                {'loss': 0.1341, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:37<00:51,  2.33it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                
                                             {'eval_loss': 0.2725510001182556, 'eval_accuracy': 0.905, 'eval_runtime': 2.6505, 'eval_samples_per_second': 377.294, 'epoch': 1.25}[A
 25%|â–ˆâ–ˆâ–Œ       | 40/160 [00:39<00:51,  2.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 26%|â–ˆâ–ˆâ–Œ       | 41/160 [00:46<06:10,  3.12s/it] 26%|â–ˆâ–ˆâ–‹       | 42/160 [00:46<04:27,  2.26s/it] 27%|â–ˆâ–ˆâ–‹       | 43/160 [00:47<03:15,  1.67s/it] 28%|â–ˆâ–ˆâ–Š       | 44/160 [00:47<02:25,  1.25s/it] 28%|â–ˆâ–ˆâ–Š       | 45/160 [00:47<01:50,  1.04it/s] 29%|â–ˆâ–ˆâ–‰       | 46/160 [00:47<01:26,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 47/160 [00:48<01:09,  1.64it/s] 30%|â–ˆâ–ˆâ–ˆ       | 48/160 [00:48<00:57,  1.96it/s] 31%|â–ˆâ–ˆâ–ˆ       | 49/160 [00:48<00:48,  2.27it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:49<00:43,  2.55it/s]                                                {'loss': 0.1945, 'learning_rate': 3.4375e-05, 'epoch': 1.56}
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:49<00:43,  2.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  6.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                                
                                             {'eval_loss': 0.2029699683189392, 'eval_accuracy': 0.926, 'eval_runtime': 2.6474, 'eval_samples_per_second': 377.735, 'epoch': 1.56}[A
 31%|â–ˆâ–ˆâ–ˆâ–      | 50/160 [00:51<00:43,  2.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 32%|â–ˆâ–ˆâ–ˆâ–      | 51/160 [00:58<05:31,  3.04s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/160 [00:58<03:58,  2.21s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/160 [00:58<02:54,  1.63s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 54/160 [00:59<02:09,  1.22s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 55/160 [00:59<01:38,  1.06it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/160 [00:59<01:17,  1.35it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 57/160 [00:59<01:01,  1.66it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 58/160 [01:00<00:51,  1.98it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 59/160 [01:00<00:44,  2.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:00<00:38,  2.58it/s]                                                {'loss': 0.1888, 'learning_rate': 3.125e-05, 'epoch': 1.88} 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:00<00:38,  2.58it/s]

  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                
                                             [A{'eval_loss': 0.3160780072212219, 'eval_accuracy': 0.892, 'eval_runtime': 2.6458, 'eval_samples_per_second': 377.952, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/160 [01:03<00:38,  2.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 38%|â–ˆâ–ˆâ–ˆâ–Š      | 61/160 [01:09<04:47,  2.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 62/160 [01:09<03:27,  2.11s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 63/160 [01:10<02:31,  1.56s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 65/160 [01:10<01:49,  1.15s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/160 [01:10<01:23,  1.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/160 [01:10<01:05,  1.42it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/160 [01:11<00:52,  1.74it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 69/160 [01:11<00:44,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:11<00:38,  2.36it/s]                                                {'loss': 0.1355, 'learning_rate': 2.8125000000000003e-05, 'epoch': 2.19}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:11<00:38,  2.36it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                {'eval_loss': 0.14782775938510895, 'eval_accuracy': 0.954, 'eval_runtime': 2.6445, 'eval_samples_per_second': 378.141, 'epoch': 2.19}
                                             [A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/160 [01:14<00:38,  2.36it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 71/160 [01:20<04:21,  2.94s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/160 [01:20<03:08,  2.14s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 73/160 [01:21<02:17,  1.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/160 [01:21<01:42,  1.19s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 75/160 [01:21<01:17,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/160 [01:22<01:00,  1.38it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 77/160 [01:22<00:48,  1.70it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 78/160 [01:22<00:40,  2.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 79/160 [01:22<00:34,  2.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:23<00:30,  2.60it/s]                                                {'loss': 0.0973, 'learning_rate': 2.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:23<00:30,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                
                                             [A{'eval_loss': 0.21229752898216248, 'eval_accuracy': 0.943, 'eval_runtime': 2.6487, 'eval_samples_per_second': 377.541, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 80/160 [01:25<00:30,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 81/160 [01:32<03:52,  2.94s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/160 [01:32<02:46,  2.14s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 83/160 [01:32<02:01,  1.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 84/160 [01:32<01:30,  1.19s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 85/160 [01:33<01:08,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 86/160 [01:33<00:53,  1.38it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 87/160 [01:33<00:43,  1.70it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 88/160 [01:33<00:35,  2.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 89/160 [01:34<00:30,  2.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:34<00:26,  2.60it/s]                                                {'loss': 0.1461, 'learning_rate': 2.1875e-05, 'epoch': 2.81}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:34<00:26,  2.60it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                
                                             {'eval_loss': 0.19608022272586823, 'eval_accuracy': 0.933, 'eval_runtime': 2.6463, 'eval_samples_per_second': 377.884, 'epoch': 2.81}[A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 90/160 [01:37<00:26,  2.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 91/160 [01:43<03:17,  2.86s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 92/160 [01:43<02:21,  2.08s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 93/160 [01:43<01:43,  1.54s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 94/160 [01:43<01:16,  1.16s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 95/160 [01:44<00:58,  1.11it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 97/160 [01:44<00:43,  1.46it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 98/160 [01:44<00:34,  1.78it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 99/160 [01:45<00:29,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:45<00:25,  2.39it/s]                                                 {'loss': 0.0199, 'learning_rate': 1.8750000000000002e-05, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:45<00:25,  2.39it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 {'eval_loss': 0.15710040926933289, 'eval_accuracy': 0.956, 'eval_runtime': 2.6477, 'eval_samples_per_second': 377.682, 'epoch': 3.12}

                                             [A 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 100/160 [01:48<00:25,  2.39it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 101/160 [01:54<02:50,  2.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/160 [01:54<02:02,  2.11s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 103/160 [01:54<01:28,  1.56s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 104/160 [01:54<01:05,  1.17s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 105/160 [01:55<00:49,  1.11it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 106/160 [01:55<00:38,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 107/160 [01:55<00:30,  1.72it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 108/160 [01:56<00:25,  2.04it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 109/160 [01:56<00:21,  2.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:56<00:19,  2.63it/s]                                                 {'loss': 0.0186, 'learning_rate': 1.5625e-05, 'epoch': 3.44}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:56<00:19,  2.63it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.07it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             {'eval_loss': 0.27664414048194885, 'eval_accuracy': 0.925, 'eval_runtime': 2.6492, 'eval_samples_per_second': 377.471, 'epoch': 3.44}
[A 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 110/160 [01:59<00:19,  2.63it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 111/160 [02:05<02:19,  2.84s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 112/160 [02:05<01:39,  2.07s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 113/160 [02:05<01:12,  1.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 114/160 [02:06<00:53,  1.16s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 115/160 [02:06<00:40,  1.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 116/160 [02:06<00:31,  1.41it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 117/160 [02:06<00:24,  1.73it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/160 [02:07<00:20,  2.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 119/160 [02:07<00:17,  2.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:07<00:15,  2.62it/s]                                                 {'loss': 0.044, 'learning_rate': 1.25e-05, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:07<00:15,  2.62it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             [A{'eval_loss': 0.15353231132030487, 'eval_accuracy': 0.959, 'eval_runtime': 2.6488, 'eval_samples_per_second': 377.529, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 120/160 [02:10<00:15,  2.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 121/160 [02:16<01:49,  2.81s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 122/160 [02:16<01:17,  2.05s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 123/160 [02:16<00:56,  1.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 124/160 [02:16<00:41,  1.15s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 125/160 [02:17<00:30,  1.13it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 126/160 [02:17<00:23,  1.43it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 127/160 [02:17<00:18,  1.74it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 129/160 [02:18<00:14,  2.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:18<00:12,  2.49it/s]                                                 {'loss': 0.0053, 'learning_rate': 9.375000000000001e-06, 'epoch': 4.06}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:18<00:12,  2.49it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             {'eval_loss': 0.21043802797794342, 'eval_accuracy': 0.946, 'eval_runtime': 2.6474, 'eval_samples_per_second': 377.728, 'epoch': 4.06}
[A 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130/160 [02:21<00:12,  2.49it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/160 [02:26<01:22,  2.83s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 132/160 [02:27<00:57,  2.07s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 133/160 [02:27<00:41,  1.53s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/160 [02:27<00:29,  1.15s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 135/160 [02:28<00:22,  1.13it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 136/160 [02:28<00:16,  1.42it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 137/160 [02:28<00:13,  1.74it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 138/160 [02:28<00:10,  2.06it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 139/160 [02:29<00:08,  2.37it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:29<00:07,  2.65it/s]                                                 {'loss': 0.0064, 'learning_rate': 6.25e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:29<00:07,  2.65it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             [A{'eval_loss': 0.1612749993801117, 'eval_accuracy': 0.959, 'eval_runtime': 2.6475, 'eval_samples_per_second': 377.715, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 140/160 [02:32<00:07,  2.65it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 141/160 [02:38<00:54,  2.88s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 142/160 [02:38<00:37,  2.10s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 143/160 [02:38<00:26,  1.56s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 144/160 [02:38<00:18,  1.17s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 145/160 [02:39<00:13,  1.11it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 146/160 [02:39<00:10,  1.39it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/160 [02:39<00:07,  1.71it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 148/160 [02:40<00:05,  2.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 149/160 [02:40<00:04,  2.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:40<00:03,  2.61it/s]                                                 {'loss': 0.006, 'learning_rate': 3.125e-06, 'epoch': 4.69}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:40<00:03,  2.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             {'eval_loss': 0.1529671847820282, 'eval_accuracy': 0.96, 'eval_runtime': 2.6514, 'eval_samples_per_second': 377.153, 'epoch': 4.69}
[A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/160 [02:43<00:03,  2.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 151/160 [02:49<00:25,  2.83s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 152/160 [02:49<00:16,  2.06s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 153/160 [02:49<00:10,  1.52s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 154/160 [02:50<00:06,  1.15s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 155/160 [02:50<00:04,  1.13it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 156/160 [02:50<00:02,  1.42it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 157/160 [02:50<00:01,  1.74it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 158/160 [02:51<00:00,  2.06it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 159/160 [02:51<00:00,  2.37it/s]                                                 {'loss': 0.0016, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:51<00:00,  2.37it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.04it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                                 
                                             [A{'eval_loss': 0.1537543088197708, 'eval_accuracy': 0.96, 'eval_runtime': 2.6507, 'eval_samples_per_second': 377.253, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [02:54<00:00,  2.37it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A                                                 {'train_runtime': 185.2818, 'train_samples_per_second': 0.864, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:04<00:00,  2.37it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [33]                   : (0.31, 5.0)
COMET INFO:     eval_accuracy [16]           : (0.614, 0.96)
COMET INFO:     eval_loss [16]               : (0.14782775938510895, 0.7786818742752075)
COMET INFO:     eval_runtime [16]            : (2.6392, 2.6514)
COMET INFO:     eval_samples_per_second [16] : (377.153, 378.906)
COMET INFO:     learning_rate [16]           : (0.0, 4.6875e-05)
COMET INFO:     loss [32]                    : (0.001510807080194354, 1.3899575471878052)
COMET INFO:     total_flos                   : 2731876085760000
COMET INFO:     train_runtime                : 185.2818
COMET INFO:     train_samples_per_second     : 0.864
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp67fe5r3b/82806f90a84946dd892a9aac735bb9a5.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [03:06<00:00,  1.16s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.82it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.52it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.66it/s]{'eval_loss': 0.1529671847820282, 'eval_accuracy': 0.96, 'eval_runtime': 2.676, 'eval_samples_per_second': 373.691, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.96
COMET INFO:     eval_loss               : 0.1529671847820282
COMET INFO:     eval_runtime            : 2.676
COMET INFO:     eval_samples_per_second : 373.691
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpdk6uqls7/eecb33fe2df0474e997321efb7aa5fa0.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<01:21,  1.03s/it]  2%|â–Ž         | 2/80 [00:01<01:08,  1.13it/s]  4%|â–         | 3/80 [00:02<01:00,  1.28it/s]  5%|â–Œ         | 4/80 [00:02<00:53,  1.41it/s]  6%|â–‹         | 5/80 [00:03<00:49,  1.52it/s]  8%|â–Š         | 6/80 [00:03<00:46,  1.60it/s]  9%|â–‰         | 7/80 [00:04<00:43,  1.67it/s] 10%|â–ˆ         | 8/80 [00:04<00:41,  1.72it/s] 11%|â–ˆâ–        | 9/80 [00:05<00:40,  1.75it/s] 12%|â–ˆâ–Ž        | 10/80 [00:05<00:39,  1.78it/s]                                               {'loss': 1.1253, 'learning_rate': 4.375e-05, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:05<00:39,  1.78it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.13it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.66it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.62it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.41it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.27it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s][A                                               
                                             [A{'eval_loss': 0.6405353546142578, 'eval_accuracy': 0.751, 'eval_runtime': 2.6296, 'eval_samples_per_second': 380.281, 'epoch': 0.62}
 12%|â–ˆâ–Ž        | 10/80 [00:08<00:39,  1.78it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s][A
                                             [A 14%|â–ˆâ–        | 11/80 [00:14<03:34,  3.11s/it] 15%|â–ˆâ–Œ        | 12/80 [00:15<02:39,  2.34s/it] 16%|â–ˆâ–‹        | 13/80 [00:16<02:00,  1.80s/it] 18%|â–ˆâ–Š        | 14/80 [00:16<01:34,  1.43s/it] 19%|â–ˆâ–‰        | 15/80 [00:17<01:15,  1.16s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:17<00:58,  1.09it/s] 21%|â–ˆâ–ˆâ–       | 17/80 [00:18<00:50,  1.24it/s] 22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:18<00:44,  1.38it/s] 24%|â–ˆâ–ˆâ–       | 19/80 [00:19<00:40,  1.49it/s] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:37,  1.58it/s]                                               {'loss': 0.4105, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:19<00:37,  1.58it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.62it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.96it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             [A{'eval_loss': 0.2990195155143738, 'eval_accuracy': 0.887, 'eval_runtime': 2.6377, 'eval_samples_per_second': 379.125, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:22<00:37,  1.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:28<03:06,  3.16s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:29<02:17,  2.38s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:29<01:44,  1.83s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:30<01:20,  1.44s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:30<01:04,  1.17s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/80 [00:31<00:53,  1.02it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:32<00:45,  1.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:32<00:39,  1.32it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:33<00:35,  1.44it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:33<00:32,  1.54it/s]                                               {'loss': 0.2226, 'learning_rate': 3.125e-05, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:33<00:32,  1.54it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.60it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.39it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               
                                             [A{'eval_loss': 0.3072042763233185, 'eval_accuracy': 0.896, 'eval_runtime': 2.6421, 'eval_samples_per_second': 378.481, 'epoch': 1.88}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:36<00:32,  1.54it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:42<02:34,  3.15s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:42<01:50,  2.31s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:43<01:23,  1.78s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/80 [00:44<01:04,  1.41s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:44<00:51,  1.15s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:45<00:42,  1.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:45<00:36,  1.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [00:46<00:31,  1.34it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [00:46<00:28,  1.46it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:47<00:25,  1.55it/s]                                               {'loss': 0.1624, 'learning_rate': 2.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:47<00:25,  1.55it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A                                               {'eval_loss': 0.24197769165039062, 'eval_accuracy': 0.909, 'eval_runtime': 2.6456, 'eval_samples_per_second': 377.982, 'epoch': 2.5}
                                             [A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [00:49<00:25,  1.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s][A
                                             [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [00:56<02:05,  3.21s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/80 [00:57<01:31,  2.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [00:57<01:08,  1.85s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [00:58<00:52,  1.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [00:58<00:41,  1.18s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [00:59<00:33,  1.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [00:59<00:28,  1.17it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:00<00:22,  1.42it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:00<00:20,  1.52it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:01<00:18,  1.61it/s]                                               {'loss': 0.0801, 'learning_rate': 1.8750000000000002e-05, 'epoch': 3.12}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:01<00:18,  1.61it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
{'eval_loss': 0.16657382249832153, 'eval_accuracy': 0.94, 'eval_runtime': 2.6503, 'eval_samples_per_second': 377.316, 'epoch': 3.12}                                             [A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/80 [01:03<00:18,  1.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:10<01:32,  3.18s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:10<01:06,  2.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:11<00:49,  1.84s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:11<00:37,  1.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:12<00:29,  1.18s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:13<00:23,  1.01it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:13<00:19,  1.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/80 [01:14<00:16,  1.32it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:14<00:14,  1.44it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:15<00:12,  1.54it/s]                                               {'loss': 0.0362, 'learning_rate': 1.25e-05, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:15<00:12,  1.54it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.08it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.63it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.95it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               {'eval_loss': 0.17232286930084229, 'eval_accuracy': 0.947, 'eval_runtime': 2.6586, 'eval_samples_per_second': 376.138, 'epoch': 3.75}
                                             [A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:17<00:12,  1.54it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:24<01:00,  3.21s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:24<00:43,  2.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:25<00:31,  1.84s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:25<00:22,  1.40s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:26<00:17,  1.14s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [01:26<00:13,  1.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:27<00:10,  1.20it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:27<00:08,  1.35it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:28<00:07,  1.47it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:29<00:06,  1.57it/s]                                               {'loss': 0.0202, 'learning_rate': 6.25e-06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:29<00:06,  1.57it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.18275055289268494, 'eval_accuracy': 0.949, 'eval_runtime': 2.6521, 'eval_samples_per_second': 377.06, 'epoch': 4.38}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:31<00:06,  1.57it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:38<00:28,  3.19s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:38<00:19,  2.40s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:39<00:12,  1.84s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/80 [01:39<00:08,  1.45s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [01:40<00:05,  1.18s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [01:40<00:03,  1.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [01:41<00:02,  1.17it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [01:41<00:01,  1.32it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [01:42<00:00,  1.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:42<00:00,  1.69it/s]                                               {'loss': 0.0161, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:42<00:00,  1.69it/s]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.1915346086025238, 'eval_accuracy': 0.94, 'eval_runtime': 2.6505, 'eval_samples_per_second': 377.281, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:45<00:00,  1.69it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A                                               {'train_runtime': 117.0328, 'train_samples_per_second': 0.684, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:56<00:00,  1.69it/s]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [17]                  : (0.62, 5.0)
COMET INFO:     eval_accuracy [8]           : (0.751, 0.949)
COMET INFO:     eval_loss [8]               : (0.16657382249832153, 0.6405353546142578)
COMET INFO:     eval_runtime [8]            : (2.6296, 2.6586)
COMET INFO:     eval_samples_per_second [8] : (376.138, 380.281)
COMET INFO:     learning_rate [8]           : (0.0, 4.375e-05)
COMET INFO:     loss [24]                   : (0.0023605041205883026, 1.1253)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 117.0328
COMET INFO:     train_samples_per_second    : 0.684
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmp5v0v4oc5/90ccd3fb81bf47d98253506f3de35dd8.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:56<00:00,  1.46s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.32it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.30it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.80it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.51it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.74it/s]{'eval_loss': 0.18275055289268494, 'eval_accuracy': 0.949, 'eval_runtime': 2.6836, 'eval_samples_per_second': 372.633, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.949
COMET INFO:     eval_loss               : 0.18275055289268494
COMET INFO:     eval_runtime            : 2.6836
COMET INFO:     eval_samples_per_second : 372.633
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpesq_2nil/b1fb8e5d5d414fae87eb847b0a3ccc97.zip
comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassificationWithPooler: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassificationWithPooler from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassificationWithPooler were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
en
fr
de
ja
zh
it
ru
es

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 0/40 [00:00<?, ?it/s]  2%|â–Ž         | 1/40 [00:01<01:01,  1.57s/it]  5%|â–Œ         | 2/40 [00:02<00:53,  1.41s/it]  8%|â–Š         | 3/40 [00:03<00:48,  1.30s/it] 10%|â–ˆ         | 4/40 [00:04<00:43,  1.22s/it] 12%|â–ˆâ–Ž        | 5/40 [00:05<00:40,  1.17s/it] 15%|â–ˆâ–Œ        | 6/40 [00:06<00:38,  1.13s/it] 18%|â–ˆâ–Š        | 7/40 [00:07<00:36,  1.10s/it] 20%|â–ˆâ–ˆ        | 8/40 [00:08<00:32,  1.03s/it] 22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:09<00:32,  1.03s/it] 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.04s/it]                                               {'loss': 1.1216, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:10<00:31,  1.04s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.13it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.65it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:01,  3.98it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.61it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.40it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.26it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A                                               
                                             [A{'eval_loss': 0.5440981388092041, 'eval_accuracy': 0.833, 'eval_runtime': 2.6383, 'eval_samples_per_second': 379.036, 'epoch': 1.25}
 25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:13<00:31,  1.04s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s][A
                                             [A 28%|â–ˆâ–ˆâ–Š       | 11/40 [00:20<01:45,  3.62s/it] 30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:21<01:19,  2.86s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:22<01:02,  2.32s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:23<00:50,  1.94s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:24<00:41,  1.68s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:34,  1.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:30,  1.32s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:27,  1.25s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:28<00:25,  1.19s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:23,  1.15s/it]                                               {'loss': 0.4407, 'learning_rate': 2.5e-05, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:23,  1.15s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.94it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.59it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.38it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.2785399258136749, 'eval_accuracy': 0.9, 'eval_runtime': 2.6475, 'eval_samples_per_second': 377.716, 'epoch': 2.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:32<00:23,  1.15s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:39<01:10,  3.70s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:40<00:52,  2.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:41<00:39,  2.35s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:42<00:30,  1.90s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:43<00:24,  1.65s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:44<00:20,  1.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:45<00:17,  1.34s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:46<00:15,  1.26s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:47<00:13,  1.19s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:48<00:11,  1.15s/it]                                               {'loss': 0.1942, 'learning_rate': 1.25e-05, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:48<00:11,  1.15s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.60it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.24it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A                                               
                                             [A{'eval_loss': 0.19477605819702148, 'eval_accuracy': 0.934, 'eval_runtime': 2.6494, 'eval_samples_per_second': 377.437, 'epoch': 3.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:51<00:11,  1.15s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s][A
                                             [A 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:58<00:32,  3.66s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:59<00:22,  2.83s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [01:00<00:16,  2.30s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [01:01<00:11,  1.93s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [01:02<00:08,  1.67s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [01:03<00:05,  1.49s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [01:04<00:04,  1.37s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [01:05<00:02,  1.27s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [01:06<00:01,  1.21s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:07<00:00,  1.10s/it]                                               {'loss': 0.1163, 'learning_rate': 0.0, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:07<00:00,  1.10s/it]
  0%|          | 0/8 [00:00<?, ?it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  6.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.59it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.58it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.37it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.23it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A                                               
{'eval_loss': 0.19946593046188354, 'eval_accuracy': 0.927, 'eval_runtime': 2.6555, 'eval_samples_per_second': 376.572, 'epoch': 5.0}
                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:10<00:00,  1.10s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s][A
                                             [A                                               {'train_runtime': 80.9123, 'train_samples_per_second': 0.494, 'epoch': 5.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:19<00:00,  1.10s/it]COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics [count] (min, max):
COMET INFO:     epoch [9]                   : (1.25, 5.0)
COMET INFO:     eval_accuracy [4]           : (0.833, 0.934)
COMET INFO:     eval_loss [4]               : (0.19477605819702148, 0.5440981388092041)
COMET INFO:     eval_runtime [4]            : (2.6383, 2.6555)
COMET INFO:     eval_samples_per_second [4] : (376.572, 379.036)
COMET INFO:     learning_rate [4]           : (0.0, 3.7500000000000003e-05)
COMET INFO:     loss [20]                   : (0.017100341618061066, 1.1216)
COMET INFO:     total_flos                  : 2731876085760000
COMET INFO:     train_runtime               : 80.9123
COMET INFO:     train_samples_per_second    : 0.494
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Parameters:
COMET INFO:     _n_gpu                       : 1
COMET INFO:     _name_or_path                : bert-base-multilingual-cased
COMET INFO:     adafactor                    : 1
COMET INFO:     adam_beta1                   : 0.9
COMET INFO:     adam_beta2                   : 0.999
COMET INFO:     adam_epsilon                 : 1e-08
COMET INFO:     add_cross_attention          : 1
COMET INFO:     architectures                : ['BertForMaskedLM']
COMET INFO:     attention_probs_dropout_prob : 0.1
COMET INFO:     bad_words_ids                : 1
COMET INFO:     bos_token_id                 : 1
COMET INFO:     chunk_size_feed_forward      : 1
COMET INFO:     dataloader_drop_last         : 1
COMET INFO:     dataloader_num_workers       : 1
COMET INFO:     dataloader_pin_memory        : True
COMET INFO:     ddp_find_unused_parameters   : 1
COMET INFO:     debug                        : 1
COMET INFO:     decoder_start_token_id       : 1
COMET INFO:     deepspeed                    : 1
COMET INFO:     directionality               : bidi
COMET INFO:     disable_tqdm                 : 1
COMET INFO:     diversity_penalty            : 1
COMET INFO:     do_eval                      : 1
COMET INFO:     do_predict                   : 1
COMET INFO:     do_sample                    : 1
COMET INFO:     do_train                     : 1
COMET INFO:     early_stopping               : 1
COMET INFO:     encoder_no_repeat_ngram_size : 1
COMET INFO:     eos_token_id                 : 1
COMET INFO:     eval_accumulation_steps      : 1
COMET INFO:     eval_steps                   : 10
COMET INFO:     evaluation_strategy          : steps
COMET INFO:     finetuning_task              : 1
COMET INFO:     fp16                         : 1
COMET INFO:     fp16_backend                 : auto
COMET INFO:     fp16_opt_level               : O1
COMET INFO:     gradient_checkpointing       : 1
COMET INFO:     greater_is_better            : True
COMET INFO:     group_by_length              : 1
COMET INFO:     hidden_act                   : gelu
COMET INFO:     hidden_dropout_prob          : 0.1
COMET INFO:     hidden_size                  : 768
COMET INFO:     id2label                     : {"0": "LABEL_0", "1": "LABEL_1", "2": "LABEL_2", "3": "LABEL_3"}
COMET INFO:     ignore_data_skip             : 1
COMET INFO:     initializer_range            : 0.02
COMET INFO:     intermediate_size            : 3072
COMET INFO:     is_decoder                   : 1
COMET INFO:     is_encoder_decoder           : 1
COMET INFO:     label2id                     : {"LABEL_0": 0, "LABEL_1": 1, "LABEL_2": 2, "LABEL_3": 3}
COMET INFO:     label_names                  : 1
COMET INFO:     label_smoothing_factor       : 1
COMET INFO:     layer_norm_eps               : 1e-12
COMET INFO:     length_penalty               : 1.0
COMET INFO:     load_best_model_at_end       : True
COMET INFO:     local_rank                   : -1
COMET INFO:     logging_dir                  : ./logs
COMET INFO:     logging_first_step           : 1
COMET INFO:     logging_steps                : 10
COMET INFO:     lr_scheduler_type            : linear
COMET INFO:     max_grad_norm                : 1.0
COMET INFO:     max_length                   : 20
COMET INFO:     max_position_embeddings      : 512
COMET INFO:     max_steps                    : -1
COMET INFO:     metric_for_best_model        : accuracy
COMET INFO:     min_length                   : 1
COMET INFO:     model_type                   : bert
COMET INFO:     no_cuda                      : 1
COMET INFO:     no_repeat_ngram_size         : 1
COMET INFO:     num_attention_heads          : 12
COMET INFO:     num_beam_groups              : 1
COMET INFO:     num_beams                    : 1
COMET INFO:     num_hidden_layers            : 12
COMET INFO:     num_return_sequences         : 1
COMET INFO:     num_train_epochs             : 5
COMET INFO:     output_attentions            : 1
COMET INFO:     output_dir                   : ./results
COMET INFO:     output_hidden_states         : 1
COMET INFO:     output_scores                : 1
COMET INFO:     overwrite_output_dir         : 1
COMET INFO:     pad_token_id                 : 1
COMET INFO:     past_index                   : -1
COMET INFO:     per_device_eval_batch_size   : 128
COMET INFO:     per_device_train_batch_size  : 32
COMET INFO:     per_gpu_eval_batch_size      : 1
COMET INFO:     per_gpu_train_batch_size     : 1
COMET INFO:     pooler_fc_size               : 768
COMET INFO:     pooler_num_attention_heads   : 12
COMET INFO:     pooler_num_fc_layers         : 3
COMET INFO:     pooler_size_per_head         : 128
COMET INFO:     pooler_type                  : avg
COMET INFO:     position_embedding_type      : absolute
COMET INFO:     prediction_loss_only         : 1
COMET INFO:     prefix                       : 1
COMET INFO:     problem_type                 : 1
COMET INFO:     pruned_heads                 : {}
COMET INFO:     remove_unused_columns        : True
COMET INFO:     repetition_penalty           : 1.0
COMET INFO:     report_to                    : ['mlflow']
COMET INFO:     return_dict                  : True
COMET INFO:     return_dict_in_generate      : 1
COMET INFO:     run_name                     : ./results
COMET INFO:     save_steps                   : 500
COMET INFO:     save_total_limit             : 1
COMET INFO:     seed                         : 42
COMET INFO:     sep_token_id                 : 1
COMET INFO:     sharded_ddp                  : 1
COMET INFO:     task_specific_params         : 1
COMET INFO:     temperature                  : 1.0
COMET INFO:     tie_encoder_decoder          : 1
COMET INFO:     tie_word_embeddings          : True
COMET INFO:     tokenizer_class              : 1
COMET INFO:     top_k                        : 50
COMET INFO:     top_p                        : 1.0
COMET INFO:     torchscript                  : 1
COMET INFO:     tpu_metrics_debug            : 1
COMET INFO:     tpu_num_cores                : 1
COMET INFO:     transformers_version         : 4.3.3
COMET INFO:     type_vocab_size              : 2
COMET INFO:     use_bfloat16                 : 1
COMET INFO:     use_cache                    : True
COMET INFO:     vocab_size                   : 119547
COMET INFO:     warmup_steps                 : 1
COMET INFO:     weight_decay                 : 1
COMET INFO:     xla_device                   : 1
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     model graph              : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Saving offline stats to disk before program termination (may take several seconds)
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmpvyzczn4z/0de2f07516ab4c71bdccc9f8bfad6ede.zip
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:20<00:00,  2.02s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:01,  5.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:01,  4.29it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  3.80it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:00,  3.49it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:01<00:00,  3.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  3.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.13it/s]COMET INFO: No Comet API Key was found, creating an OfflineExperiment. Set up your API Key to get the full Comet experience https://www.comet.ml/docs/python-sdk/advanced/#python-configuration
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.69it/s]{'eval_loss': 0.19477605819702148, 'eval_accuracy': 0.934, 'eval_runtime': 2.6915, 'eval_samples_per_second': 371.537, 'epoch': 5.0}

COMET INFO: ----------------------------------
COMET INFO: Comet.ml OfflineExperiment Summary
COMET INFO: ----------------------------------
COMET INFO:   Data:
COMET INFO:     display_summary_level : 1
COMET INFO:     url                   : [OfflineExperiment will get URL after upload]
COMET INFO:   Metrics:
COMET INFO:     epoch                   : 5.0
COMET INFO:     eval_accuracy           : 0.934
COMET INFO:     eval_loss               : 0.19477605819702148
COMET INFO:     eval_runtime            : 2.6915
COMET INFO:     eval_samples_per_second : 371.537
COMET INFO:   Others:
COMET INFO:     Created from       : MLFlow auto-logger
COMET INFO:     offline_experiment : True
COMET INFO:   Uploads:
COMET INFO:     environment details      : 1
COMET INFO:     filename                 : 1
COMET INFO:     git metadata             : 1
COMET INFO:     git-patch (uncompressed) : 1 (566 bytes)
COMET INFO:     installed packages       : 1
COMET INFO:     os packages              : 1
COMET INFO:     source_code              : 1
COMET INFO: ----------------------------------
COMET INFO: Starting saving the offline archive
COMET INFO: To upload this offline experiment, run:
    comet upload /tmp/tmppo9ru0bj/3b5651ab01e54827bd29fc4eac7cb350.zip
